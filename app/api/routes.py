"""
FastAPI —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤.
"""

from typing import Optional
from fastapi import APIRouter, HTTPException, Depends

from app.models.api import (
    SearchRequest,
    SearchResponse,
    HealthResponse,
    APIInfoResponse,
    SearchWithLLMResponse,
    CandidateWithLLMAnalysis,
    LLMAnalysisResult,
)
from app.models.cv import CVOutput, WorkExperience
from app.services.cv_parser import CVParser
from app.services.search import search_candidates
from app.services.llm_analyze import LLMAnalyzer


router = APIRouter()

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è CVParser (–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –≤ lifespan)
_cv_parser: Optional[CVParser] = None


def get_cv_parser() -> CVParser:
    """Dependency –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è CVParser"""
    if _cv_parser is None:
        raise HTTPException(status_code=503, detail="CVParser –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    return _cv_parser


def set_cv_parser(parser: CVParser):
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ CVParser"""
    global _cv_parser
    _cv_parser = parser


def clear_cv_parser():
    """–û—á–∏—Å—Ç–∫–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ CVParser"""
    global _cv_parser
    _cv_parser = None


@router.get("/", response_model=APIInfoResponse, tags=["Info"])
async def root():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± API"""
    return APIInfoResponse(
        name="CV Search API",
        version="1.0.0",
        description="API –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ —Ç–µ–∫—Å—Ç—É –≤–∞–∫–∞–Ω—Å–∏–∏",
        endpoints={
            "POST /search": "–ü–æ–∏—Å–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ —Ç–µ–∫—Å—Ç—É –≤–∞–∫–∞–Ω—Å–∏–∏",
            "POST /search/with-llm-analysis": "–ü–æ–∏—Å–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —Å LLM –∞–Ω–∞–ª–∏–∑–æ–º —Ç–æ–ø-5",
            "GET /health": "–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–∞",
            "GET /": "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± API"
        }
    )


@router.get("/health", response_model=HealthResponse, tags=["Health"])
async def health_check(parser: CVParser = Depends(get_cv_parser)):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–∞"""
    try:
        collection_info = parser.qdrant_client.get_collection(parser.collection_name)
        
        return HealthResponse(
            status="healthy",
            collection=parser.collection_name,
            documents_count=collection_info.points_count,
            sparse_fitted=parser._sparse_fitted,
            sparse_method=parser.sparse_method
        )
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Qdrant: {str(e)}")


@router.post("/search", response_model=SearchResponse, tags=["Search"])
async def search(request: SearchRequest, parser: CVParser = Depends(get_cv_parser)):
    """
    –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ —Ç–µ–∫—Å—Ç—É –≤–∞–∫–∞–Ω—Å–∏–∏
    
    - **vacancy_text**: –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ (—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏, –Ω–∞–≤—ã–∫–∏)
    - **search_mode**: –†–µ–∂–∏–º –ø–æ–∏—Å–∫–∞
        - `dense` - —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Voyage AI embeddings
        - `sparse` - keyword –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ TF-IDF
        - `hybrid` - –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –æ–±–æ–∏—Ö –º–µ—Ç–æ–¥–æ–≤ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
    - **top_k**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ (1-50)
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏.
    """
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º –ø–æ–∏—Å–∫–∞
    actual_mode = request.search_mode
    if actual_mode in ["sparse", "hybrid"] and not parser._sparse_fitted:
        actual_mode = "dense" if request.search_mode == "hybrid" else request.search_mode
    
    candidates = search_candidates(
        parser=parser,
        query_text=request.vacancy_text,
        top_k=request.top_k,
        search_mode=request.search_mode
    )
    
    return SearchResponse(
        query_preview=request.vacancy_text[:100] + "..." if len(request.vacancy_text) > 100 else request.vacancy_text,
        search_mode=actual_mode,
        results_count=len(candidates),
        candidates=candidates
    )


@router.post("/search/with-llm-analysis", response_model=SearchWithLLMResponse, tags=["Search"])
async def search_with_llm_analysis(
    request: SearchRequest,
    parser: CVParser = Depends(get_cv_parser)
):
    """
    –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —Å LLM –∞–Ω–∞–ª–∏–∑–æ–º —Ç–æ–ø-5
    
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –¥–≤–∞ —ç—Ç–∞–ø–∞:
    1. **–í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫** - –Ω–∞—Ö–æ–¥–∏—Ç —Ç–æ–ø-K –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ Qdrant (dense/sparse/hybrid)
    2. **LLM –∞–Ω–∞–ª–∏–∑** - –¥–ª—è —Ç–æ–ø-5 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ–ª—É—á–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É —á–µ—Ä–µ–∑ GPT-4
    
    LLM –∞–Ω–∞–ª–∏–∑ –≤–∫–ª—é—á–∞–µ—Ç:
    - –û—Ü–µ–Ω–∫—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (0-1) –Ω–∞ –æ—Å–Ω–æ–≤–µ 4 –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤
    - –°–∏–ª—å–Ω—ã–µ –∏ —Å–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
    - –ö–ª—é—á–µ–≤—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏
    - –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
    - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –∏ –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ
    
    **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
    - **vacancy_text**: –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏
    - **search_mode**: dense/sparse/hybrid (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è hybrid)
    - **top_k**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (1-50)
    
    **‚ö†Ô∏è –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ**: LLM –∞–Ω–∞–ª–∏–∑ –∑–∞–Ω–∏–º–∞–µ—Ç ~3-5 —Å–µ–∫—É–Ω–¥ –Ω–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
    """
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º –ø–æ–∏—Å–∫–∞
    actual_mode = request.search_mode
    if actual_mode in ["sparse", "hybrid"] and not parser._sparse_fitted:
        actual_mode = "dense" if request.search_mode == "hybrid" else request.search_mode
    
    # –®–∞–≥ 1: –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    print(f"üîç –ü–æ–∏—Å–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ {actual_mode}...")
    candidates = search_candidates(
        parser=parser,
        query_text=request.vacancy_text,
        top_k=request.top_k,
        search_mode=request.search_mode
    )
    
    if not candidates:
        return SearchWithLLMResponse(
            query_preview=request.vacancy_text[:100] + "..." if len(request.vacancy_text) > 100 else request.vacancy_text,
            search_mode=actual_mode,
            results_count=0,
            llm_analyzed_count=0,
            candidates=[]
        )
    
    # –®–∞–≥ 2: LLM –∞–Ω–∞–ª–∏–∑ —Ç–æ–ø-5 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    top_n = min(5, len(candidates))
    print(f"ü§ñ LLM –∞–Ω–∞–ª–∏–∑ —Ç–æ–ø-{top_n} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤...")
    
    analyzer = LLMAnalyzer(model="gpt-4o", temperature=0.3)
    
    candidates_with_llm = []
    
    for i, candidate in enumerate(candidates, 1):
        # –î–ª—è —Ç–æ–ø-5 –¥–æ–±–∞–≤–ª—è–µ–º LLM –∞–Ω–∞–ª–∏–∑
        if i <= top_n:
            try:
                print(f"   [{i}/{top_n}] –ê–Ω–∞–ª–∏–∑: {candidate.full_name}...")
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º CandidateResult –≤ CVOutput –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                cv_data = CVOutput(
                    full_name=candidate.full_name,
                    email=candidate.email,
                    phone=candidate.phone,
                    location=candidate.location,
                    summary=candidate.summary,
                    total_experience_months=candidate.total_experience_months,
                    work_history=[
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º WorkExperienceResponse –æ–±—Ä–∞—Ç–Ω–æ –≤ WorkExperience
                        WorkExperience(
                            role=w.role,
                            company=w.company,
                            start_date=w.start_date,
                            end_date=w.end_date,
                            description=w.description,
                            technologies=w.technologies
                        )
                        for w in candidate.work_history
                    ],
                    education=[],  # –£–ø—Ä–æ—â–∞–µ–º –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                    skills=candidate.skills,
                    languages=candidate.languages
                )
                
                # LLM –∞–Ω–∞–ª–∏–∑
                llm_result = analyzer.analyze_match(cv_data, request.vacancy_text)
                
                # –°–æ–∑–¥–∞–µ–º CandidateWithLLMAnalysis
                candidate_with_llm = CandidateWithLLMAnalysis(
                    **candidate.dict(),
                    llm_analysis=LLMAnalysisResult(
                        relevance_score=llm_result.relevance_score,
                        overall_assessment=llm_result.overall_assessment,
                        summary=llm_result.summary,
                        strengths=llm_result.strengths,
                        weaknesses=llm_result.weaknesses,
                        key_matches=llm_result.key_matches,
                        missing_requirements=llm_result.missing_requirements,
                        recommendation=llm_result.recommendation,
                        reasoning=llm_result.reasoning
                    )
                )
                
                print(f"      ‚úÖ LLM Score: {llm_result.relevance_score:.3f}")
                
            except Exception as e:
                print(f"      ‚ö†Ô∏è –û—à–∏–±–∫–∞ LLM –∞–Ω–∞–ª–∏–∑–∞: {e}")
                # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ - –¥–æ–±–∞–≤–ª—è–µ–º –±–µ–∑ LLM –∞–Ω–∞–ª–∏–∑–∞
                candidate_with_llm = CandidateWithLLMAnalysis(**candidate.dict())
        else:
            # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã –±–µ–∑ LLM –∞–Ω–∞–ª–∏–∑–∞
            candidate_with_llm = CandidateWithLLMAnalysis(**candidate.dict())
        
        candidates_with_llm.append(candidate_with_llm)
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–∫–æ–ª—å–∫–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ
    llm_analyzed = sum(1 for c in candidates_with_llm if c.llm_analysis is not None)
    
    print(f"‚úÖ –ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(candidates_with_llm)} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤, {llm_analyzed} —Å LLM –∞–Ω–∞–ª–∏–∑–æ–º")
    
    return SearchWithLLMResponse(
        query_preview=request.vacancy_text[:100] + "..." if len(request.vacancy_text) > 100 else request.vacancy_text,
        search_mode=actual_mode,
        results_count=len(candidates_with_llm),
        llm_analyzed_count=llm_analyzed,
        candidates=candidates_with_llm
    )
