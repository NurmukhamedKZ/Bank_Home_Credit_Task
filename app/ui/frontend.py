"""
Streamlit —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ –≤–∞–∫–∞–Ω—Å–∏–∏.

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç—Ä–∏ –º–µ—Ç–æ–¥–∞ –ø–æ–∏—Å–∫–∞:
    1. Vector Search (Dense/Sparse/Hybrid)
    2. ML Classifier (TF-IDF + Logistic Regression)
    3. LLM Analyzer (GPT-4 —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏)

–ó–∞–ø—É—Å–∫:
    streamlit run app/ui/frontend.py

–¢—Ä–µ–±—É–µ—Ç –∑–∞–ø—É—â–µ–Ω–Ω–æ–≥–æ API —Å–µ—Ä–≤–µ—Ä–∞:
    uvicorn app.main:app --port 8000
"""

import streamlit as st
import requests
from typing import Optional
import os

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è - —á–∏—Ç–∞–µ–º –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è Docker
API_URL = os.environ.get("API_URL", "http://localhost:8000")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="CV Search - –ü–æ–∏—Å–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤",
    page_icon="üîç",
    layout="wide"
)


# ==================== API –í–´–ó–û–í–´ ====================

def check_api_health() -> Optional[dict]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ API"""
    try:
        response = requests.get(f"{API_URL}/health", timeout=5)
        if response.status_code == 200:
            return response.json()
        return None
    except requests.exceptions.RequestException:
        return None


def api_vector_search(vacancy_text: str, search_mode: str, top_k: int) -> Optional[dict]:
    """Vector Search —á–µ—Ä–µ–∑ /search"""
    try:
        response = requests.post(
            f"{API_URL}/search",
            json={"vacancy_text": vacancy_text, "search_mode": search_mode, "top_k": top_k},
            timeout=60
        )
        if response.status_code == 200:
            return response.json()
        st.error(f"–û—à–∏–±–∫–∞ API: {response.status_code} - {response.text}")
        return None
    except requests.exceptions.RequestException as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
        return None


def api_ml_classifier(vacancy_text: str, top_k: int, threshold: float) -> Optional[dict]:
    """ML Classifier —á–µ—Ä–µ–∑ /search/ml-classifier"""
    try:
        response = requests.post(
            f"{API_URL}/search/ml-classifier",
            json={"vacancy_text": vacancy_text, "top_k": top_k, "threshold": threshold},
            timeout=60
        )
        if response.status_code == 200:
            return response.json()
        st.error(f"–û—à–∏–±–∫–∞ API: {response.status_code} - {response.text}")
        return None
    except requests.exceptions.RequestException as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
        return None


def api_llm_analysis(vacancy_text: str, search_mode: str, top_k: int) -> Optional[dict]:
    """LLM Analyzer —á–µ—Ä–µ–∑ /search/with-llm-analysis"""
    try:
        response = requests.post(
            f"{API_URL}/search/with-llm-analysis",
            json={"vacancy_text": vacancy_text, "search_mode": search_mode, "top_k": top_k},
            timeout=180
        )
        if response.status_code == 200:
            return response.json()
        st.error(f"–û—à–∏–±–∫–∞ API: {response.status_code} - {response.text}")
        return None
    except requests.exceptions.RequestException as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
        return None


# ==================== –£–¢–ò–õ–ò–¢–´ ====================

def format_experience(months: int) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã"""
    if months < 12:
        return f"{months} –º–µ—Å."
    years = months // 12
    remaining_months = months % 12
    if remaining_months == 0:
        return f"{years} –ª–µ—Ç" if years > 4 else f"{years} –≥–æ–¥–∞"
    return f"{years} –≥. {remaining_months} –º–µ—Å."


# ==================== –†–ï–ù–î–ï–†–ò–ù–ì –ö–ê–†–¢–û–ß–ï–ö ====================

def render_candidate_card(candidate: dict):
    """–ë–∞–∑–æ–≤–∞—è –∫–∞—Ä—Ç–æ—á–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞"""
    score = candidate.get("score", 0)
    score_color = "green" if score >= 0.7 else ("orange" if score >= 0.5 else "red")

    col1, col2 = st.columns([4, 1])
    with col1:
        st.markdown(f"### {candidate.get('rank', '?')}. {candidate.get('full_name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
    with col2:
        st.markdown(f"**Score:** :{score_color}[{score:.4f}]")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã", format_experience(candidate.get("total_experience_months", 0)))
    with col2:
        st.metric("–ù–∞–≤—ã–∫–æ–≤", len(candidate.get("skills", [])))
    with col3:
        loc = ", ".join(candidate.get("location", [])[:2]) or "–ù–µ —É–∫–∞–∑–∞–Ω–∞"
        st.metric("–õ–æ–∫–∞—Ü–∏—è", loc)

    contacts = []
    if candidate.get("email"):
        contacts.append(f"üìß {candidate['email']}")
    if candidate.get("phone"):
        contacts.append(f"üì± {candidate['phone']}")
    if contacts:
        st.markdown(" | ".join(contacts))

    if candidate.get("summary"):
        summary = candidate["summary"]
        st.markdown(f"**–û –∫–∞–Ω–¥–∏–¥–∞—Ç–µ:** {summary[:300]}{'...' if len(summary) > 300 else ''}")

    if candidate.get("skills"):
        skills = candidate["skills"][:15]
        st.markdown("**–ù–∞–≤—ã–∫–∏:** " + ", ".join(f"`{s}`" for s in skills))
        if len(candidate["skills"]) > 15:
            st.caption(f"... –∏ –µ—â—ë {len(candidate['skills']) - 15} –Ω–∞–≤—ã–∫–æ–≤")

    if candidate.get("links"):
        links_md = " | ".join([f"[{l.split('//')[-1][:30]}]({l})" for l in candidate["links"][:3]])
        st.markdown(f"**–°—Å—ã–ª–∫–∏:** {links_md}")

    with st.expander("üìã –ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"):
        if candidate.get("languages"):
            st.markdown(f"**–Ø–∑—ã–∫–∏:** {', '.join(candidate['languages'])}")

        if candidate.get("work_history"):
            st.markdown("#### –ò—Å—Ç–æ—Ä–∏—è —Ä–∞–±–æ—Ç—ã")
            for i, work in enumerate(candidate["work_history"][:5], 1):
                st.markdown(
                    f"**{i}. {work.get('role', '–î–æ–ª–∂–Ω–æ—Å—Ç—å')}** @ {work.get('company', '–ö–æ–º–ø–∞–Ω–∏—è')}  \n"
                    f"üìÖ {work.get('start_date', '?')} ‚Äî {work.get('end_date', '?')}  \n"
                    f"{work.get('description', '')[:200]}"
                )
                if work.get("technologies"):
                    st.markdown("–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏: " + ", ".join(f"`{t}`" for t in work["technologies"][:10]))
                st.divider()

        if candidate.get("source_file"):
            st.caption(f"ID —Ñ–∞–π–ª–∞: {candidate['source_file']}")


def render_ml_badge(candidate: dict):
    """–ë–µ–π–¥–∂ ML –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞"""
    ml_prob = candidate.get("ml_probability", 0)
    ml_pred = candidate.get("ml_prediction", 0)

    if ml_pred == 1:
        st.success(f"ML: –†–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω (p={ml_prob:.3f})")
    else:
        st.warning(f"ML: –ù–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω (p={ml_prob:.3f})")


def render_llm_analysis(llm: dict):
    """–ë–ª–æ–∫ LLM –∞–Ω–∞–ª–∏–∑–∞"""
    if not llm:
        return

    score = llm.get("relevance_score", 0)
    score_color = "green" if score >= 0.75 else ("orange" if score >= 0.5 else "red")

    st.markdown(f"#### ü§ñ LLM –ê–Ω–∞–ª–∏–∑")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("LLM Score", f"{score:.3f}")
    with col2:
        assessment_map = {
            "excellent": "üåü –û—Ç–ª–∏—á–Ω—ã–π",
            "good": "‚úÖ –•–æ—Ä–æ—à–∏–π",
            "moderate": "‚ö†Ô∏è –°—Ä–µ–¥–Ω–∏–π",
            "poor": "‚ùå –°–ª–∞–±—ã–π"
        }
        st.metric("–û—Ü–µ–Ω–∫–∞", assessment_map.get(llm.get("overall_assessment", ""), llm.get("overall_assessment", "")))
    with col3:
        rec_map = {
            "strongly_recommend": "üü¢ –†–µ–∫–æ–º–µ–Ω–¥—É—é",
            "recommend": "üü° –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å",
            "consider": "üü† –í–æ–∑–º–æ–∂–Ω–æ",
            "not_recommend": "üî¥ –ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é"
        }
        st.metric("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è", rec_map.get(llm.get("recommendation", ""), llm.get("recommendation", "")))

    st.markdown(f"**–†–µ–∑—é–º–µ:** {llm.get('summary', '')}")

    col_left, col_right = st.columns(2)

    with col_left:
        st.markdown("**‚úÖ –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:**")
        for s in llm.get("strengths", []):
            st.markdown(f"- {s}")

        st.markdown("**üéØ –ö–ª—é—á–µ–≤—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è:**")
        for m in llm.get("key_matches", []):
            st.markdown(f"- {m}")

    with col_right:
        st.markdown("**‚ö†Ô∏è –°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:**")
        for w in llm.get("weaknesses", []):
            st.markdown(f"- {w}")

        st.markdown("**‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:**")
        for m in llm.get("missing_requirements", []):
            st.markdown(f"- {m}")

    with st.expander("üí≠ –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ"):
        st.markdown(llm.get("reasoning", ""))


# ==================== –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø ====================

def main():
    st.title("üîç –ü–æ–∏—Å–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ –≤–∞–∫–∞–Ω—Å–∏–∏")
    st.markdown("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ –∏ –≤—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞.")

    health = check_api_health()

    # ==================== SIDEBAR ====================
    with st.sidebar:
        st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")

        if health:
            st.success("‚úÖ API –ø–æ–¥–∫–ª—é—á–µ–Ω")
            st.caption(f"–î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {health.get('documents_count', 0)}")
            st.caption(f"Sparse: {'‚úÖ' if health.get('sparse_fitted') else '‚ùå'} ({health.get('sparse_method', 'tfidf')})")
        else:
            st.error("‚ùå API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            st.code("uvicorn app.main:app --port 8000")

        st.divider()

        # –í—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞ –ø–æ–∏—Å–∫–∞
        search_method = st.radio(
            "–ú–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞",
            options=["vector", "ml_classifier", "llm_analysis"],
            format_func=lambda x: {
                "vector": "üîÄ Vector Search (–±—ã—Å—Ç—Ä—ã–π)",
                "ml_classifier": "ü§ñ ML Classifier (TF-IDF)",
                "llm_analysis": "üß† LLM Analyzer (GPT-4)"
            }[x],
            help="""
**Vector Search** - —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π + keyword –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Qdrant (~0.2 —Å–µ–∫)

**ML Classifier** - supervised learning –Ω–∞ TF-IDF (~1-2 —Å–µ–∫)

**LLM Analyzer** - GPT-4 —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º —Ç–æ–ø-5 (~15-20 —Å–µ–∫)
            """
        )

        st.divider()

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–µ—Ç–æ–¥–∞
        if search_method == "vector":
            search_mode = st.selectbox(
                "–†–µ–∂–∏–º",
                options=["hybrid", "dense", "sparse"],
                format_func=lambda x: {
                    "hybrid": "üîÄ Hybrid (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)",
                    "dense": "üß† Dense (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π)",
                    "sparse": "üìù Sparse (–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞)"
                }[x]
            )
            top_k = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤", 1, 30, 10)

        elif search_method == "ml_classifier":
            top_k = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤", 1, 30, 10)
            threshold = st.slider("–ü–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏", 0.0, 1.0, 0.5, 0.05,
                                  help="–ö–∞–Ω–¥–∏–¥–∞—Ç—ã —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ —Å—á–∏—Ç–∞—é—Ç—Å—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º–∏")

        elif search_method == "llm_analysis":
            search_mode = st.selectbox(
                "–†–µ–∂–∏–º –ø–æ–∏—Å–∫–∞",
                options=["hybrid", "dense", "sparse"],
                format_func=lambda x: {
                    "hybrid": "üîÄ Hybrid",
                    "dense": "üß† Dense",
                    "sparse": "üìù Sparse"
                }[x]
            )
            top_k = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤", 1, 15, 5)
            st.warning("‚è± LLM –∞–Ω–∞–ª–∏–∑ –∑–∞–Ω–∏–º–∞–µ—Ç ~3-5 —Å–µ–∫ –Ω–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞")

        st.divider()
        st.markdown("### üìñ –ú–µ—Ç–æ–¥—ã –ø–æ–∏—Å–∫–∞")
        st.markdown("""
| –ú–µ—Ç–æ–¥ | –°–∫–æ—Ä–æ—Å—Ç—å | –û–±—ä—è—Å–Ω–µ–Ω–∏—è |
|-------|----------|------------|
| Vector | ‚ö°‚ö°‚ö° | ‚ùå |
| ML | ‚ö°‚ö° | ‚ùå |
| LLM | üêå | ‚úÖ |
        """)

    # ==================== MAIN AREA ====================
    if not health:
        st.warning("‚ö†Ô∏è API —Å–µ—Ä–≤–µ—Ä –Ω–µ –∑–∞–ø—É—â–µ–Ω.")
        st.code("uvicorn app.main:app --port 8000", language="bash")
        return

    vacancy_text = st.text_area(
        "–¢–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏",
        height=200,
        placeholder="–í—Å—Ç–∞–≤—å—Ç–µ —Å—é–¥–∞ —Ç–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏...\n\n–ù–∞–ø—Ä–∏–º–µ—Ä:\n–ò—â–µ–º Python —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞ —Å –æ–ø—ã—Ç–æ–º FastAPI, PostgreSQL, Docker..."
    )

    col1, col2, _ = st.columns([1, 1, 2])
    with col1:
        search_button = st.button("üîç –ù–∞–π—Ç–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤", type="primary", use_container_width=True)
    with col2:
        if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å", use_container_width=True):
            st.rerun()

    # ==================== –ü–û–ò–°–ö ====================
    if search_button:
        if not vacancy_text or len(vacancy_text.strip()) < 10:
            st.warning("‚ö†Ô∏è –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ (–º–∏–Ω–∏–º—É–º 10 —Å–∏–º–≤–æ–ª–æ–≤)")
            return

        # –í—ã–±–∏—Ä–∞–µ–º API –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–µ—Ç–æ–¥–∞
        if search_method == "vector":
            with st.spinner("üîç Vector Search..."):
                result = api_vector_search(vacancy_text, search_mode, top_k)
            method_label = f"üîÄ Vector Search ({search_mode})"

        elif search_method == "ml_classifier":
            with st.spinner("ü§ñ ML –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è..."):
                result = api_ml_classifier(vacancy_text, top_k, threshold)
            method_label = "ü§ñ ML Classifier"

        elif search_method == "llm_analysis":
            with st.spinner("üß† LLM –∞–Ω–∞–ª–∏–∑ (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –¥–æ –º–∏–Ω—É—Ç—ã)..."):
                result = api_llm_analysis(vacancy_text, search_mode, top_k)
            method_label = "üß† LLM Analyzer"

        if not result:
            return

        # ==================== –†–ï–ó–£–õ–¨–¢–ê–¢–´ ====================
        st.divider()

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("–ù–∞–π–¥–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤", result.get("results_count", 0))
        with col2:
            st.metric("–ú–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞", method_label)
        with col3:
            if search_method == "ml_classifier":
                st.metric("–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö", f"{result.get('relevant_count', 0)} / {result.get('results_count', 0)}")
            elif search_method == "llm_analysis":
                st.metric("LLM –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ", result.get("llm_analyzed_count", 0))
            else:
                st.metric("–ó–∞–ø—Ä–æ—Å", f"{len(vacancy_text)} —Å–∏–º–≤–æ–ª–æ–≤")

        st.divider()

        candidates = result.get("candidates", [])
        if not candidates:
            st.info("üòî –ö–∞–Ω–¥–∏–¥–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
            return

        st.subheader(f"üë• –¢–æ–ø-{len(candidates)} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")

        # –¢–∞–±—ã: –∫–∞—Ä—Ç–æ—á–∫–∏ / —Ç–∞–±–ª–∏—Ü–∞
        tab1, tab2 = st.tabs(["üìã –ö–∞—Ä—Ç–æ—á–∫–∏", "üìä –¢–∞–±–ª–∏—Ü–∞"])

        with tab1:
            for candidate in candidates:
                with st.container():
                    # –ë–∞–∑–æ–≤–∞—è –∫–∞—Ä—Ç–æ—á–∫–∞
                    render_candidate_card(candidate)

                    # ML –±–µ–π–¥–∂ (–¥–ª—è ML –º–µ—Ç–æ–¥–∞)
                    if search_method == "ml_classifier":
                        render_ml_badge(candidate)

                    # LLM –∞–Ω–∞–ª–∏–∑ (–¥–ª—è LLM –º–µ—Ç–æ–¥–∞)
                    if search_method == "llm_analysis" and candidate.get("llm_analysis"):
                        render_llm_analysis(candidate["llm_analysis"])

                    st.divider()

        with tab2:
            table_data = []
            for c in candidates:
                row = {
                    "–†–∞–Ω–≥": c.get("rank"),
                    "Score": f"{c.get('score', 0):.4f}",
                    "–ò–º—è": c.get("full_name", ""),
                    "–û–ø—ã—Ç": format_experience(c.get("total_experience_months", 0)),
                    "–ù–∞–≤—ã–∫–æ–≤": len(c.get("skills", [])),
                    "Email": c.get("email", "-"),
                    "–õ–æ–∫–∞—Ü–∏—è": ", ".join(c.get("location", [])[:2]) or "-"
                }

                if search_method == "ml_classifier":
                    row["ML Prob"] = f"{c.get('ml_probability', 0):.3f}"
                    row["–†–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω"] = "‚úÖ" if c.get("ml_prediction") == 1 else "‚ùå"

                if search_method == "llm_analysis" and c.get("llm_analysis"):
                    llm = c["llm_analysis"]
                    row["LLM Score"] = f"{llm.get('relevance_score', 0):.3f}"
                    row["–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è"] = llm.get("recommendation", "-")

                table_data.append(row)

            st.dataframe(table_data, use_container_width=True, hide_index=True)

        # Raw JSON
        with st.expander("üîß Raw JSON Response"):
            st.json(result)


if __name__ == "__main__":
    main()
