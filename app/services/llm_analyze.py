"""
LLM Analyzer - –∞–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –≤–∞–∫–∞–Ω—Å–∏–∏ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏.

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç LLM –¥–ª—è:
- –û—Ü–µ–Ω–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ (0-1)
- –ì–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
- –í—ã–¥–µ–ª–µ–Ω–∏—è —Å–∏–ª—å–Ω—ã—Ö –∏ —Å–ª–∞–±—ã—Ö —Å—Ç–æ—Ä–æ–Ω
"""

import os
from typing import List, Optional
from pathlib import Path

from dotenv import load_dotenv
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

from app.models.cv import CVOutput

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")


# ==================== PYDANTIC –ú–û–î–ï–õ–ò ====================

class MatchAnalysis(BaseModel):
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –≤–∞–∫–∞–Ω—Å–∏–∏"""
    
    relevance_score: float = Field(
        ge=0.0,
        le=1.0,
        description="–û—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –æ—Ç 0.0 (–Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç) –¥–æ 1.0 (–∏–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç)"
    )
    
    overall_assessment: str = Field(
        description="–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: 'excellent', 'good', 'moderate', 'poor'"
    )
    
    summary: str = Field(
        description="–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –≤–∞–∫–∞–Ω—Å–∏–∏"
    )
    
    strengths: List[str] = Field(
        description="–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–∏ (3-5 –ø—É–Ω–∫—Ç–æ–≤)"
    )
    
    weaknesses: List[str] = Field(
        description="–°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –∏–ª–∏ –ø—Ä–æ–±–µ–ª—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π (2-4 –ø—É–Ω–∫—Ç–∞)"
    )
    
    key_matches: List[str] = Field(
        description="–ö–ª—é—á–µ–≤—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–∞–≤—ã–∫–æ–≤ –∏ –æ–ø—ã—Ç–∞ —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ (3-5 –ø—É–Ω–∫—Ç–æ–≤)"
    )
    
    missing_requirements: List[str] = Field(
        description="–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è (2-4 –ø—É–Ω–∫—Ç–∞)"
    )
    
    recommendation: str = Field(
        description="–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: 'strongly_recommend', 'recommend', 'consider', 'not_recommend'"
    )
    
    reasoning: str = Field(
        description="–î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (4-6 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π)"
    )


# ==================== LLM ANALYZER ====================

class LLMAnalyzer:
    """
    –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –≤–∞–∫–∞–Ω—Å–∏–∏ —á–µ—Ä–µ–∑ LLM.
    –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏.
    """
    
    def __init__(self, model: str = "gpt-4o", temperature: float = 0.3):
        """
        Args:
            model: –ú–æ–¥–µ–ª—å OpenAI –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (0.0-1.0)
        """
        self.model_name = model
        self.temperature = temperature
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM
        self.llm = ChatOpenAI(
            model=model,
            api_key=OPENAI_API_KEY,
            temperature=temperature
        )
        
        self.structured_llm = self.llm.with_structured_output(MatchAnalysis)
        
        # System prompt –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        self.system_prompt = """You are an expert technical recruiter and talent analyst with deep knowledge of IT roles.

Your task is to analyze how well a candidate matches a job vacancy, providing:
1. A relevance score (0.0 to 1.0)
2. Detailed explanation of strengths and weaknesses
3. Key matching points and missing requirements
4. A clear recommendation

EVALUATION CRITERIA:
- Technical skills match (40%): Required vs actual skills, experience with specific technologies
- Experience level (25%): Years of experience, seniority, role complexity
- Domain fit (20%): Industry experience, project types, team size
- Soft skills & culture (15%): Communication, leadership, teamwork indicators

SCORING GUIDELINES:
- 0.9-1.0: Exceptional match, exceeds requirements
- 0.75-0.89: Strong match, meets most requirements with some extras
- 0.6-0.74: Good match, meets core requirements
- 0.4-0.59: Moderate match, missing some key requirements
- 0.2-0.39: Weak match, significant gaps
- 0.0-0.19: Poor match, fundamentally misaligned

Be objective, specific, and constructive. Focus on facts from the CV and job requirements."""
        
        # –°–æ–∑–¥–∞–µ–º prompt template
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", self.system_prompt),
            ("user", """Analyze the match between this candidate and job vacancy.

JOB VACANCY:
{vacancy_text}

CANDIDATE CV:
Full Name: {full_name}
Total Experience: {experience_months} months ({experience_years} years)

Summary: {summary}

Skills: {skills}

Work History:
{work_history}

Education:
{education}

Languages: {languages}

Provide a comprehensive analysis with relevance score, strengths, weaknesses, and recommendation.""")
        ])
        
        # –°–æ–∑–¥–∞–µ–º —Ü–µ–ø–æ—á–∫—É
        self.chain = self.prompt | self.structured_llm
    
    def analyze_match(
        self,
        cv_data: CVOutput,
        vacancy_text: str
    ) -> MatchAnalysis:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –≤–∞–∫–∞–Ω—Å–∏–∏
        
        Args:
            cv_data: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ CV
            vacancy_text: –¢–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏
            
        Returns:
            MatchAnalysis —Å –æ—Ü–µ–Ω–∫–æ–π –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏
        """
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ CV –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
        experience_years = cv_data.total_experience_months / 12
        
        skills_str = ", ".join(cv_data.skills) if cv_data.skills else "Not specified"
        
        work_history_str = self._format_work_history(cv_data.work_history)
        education_str = self._format_education(cv_data.education)
        languages_str = ", ".join(cv_data.languages) if cv_data.languages else "Not specified"
        
        # –í—ã–∑—ã–≤–∞–µ–º LLM
        analysis = self.chain.invoke({
            "vacancy_text": vacancy_text,
            "full_name": cv_data.full_name,
            "experience_months": cv_data.total_experience_months,
            "experience_years": f"{experience_years:.1f}",
            "summary": cv_data.summary or "Not provided",
            "skills": skills_str,
            "work_history": work_history_str,
            "education": education_str,
            "languages": languages_str
        })
        
        return analysis
    
    def analyze_multiple(
        self,
        candidates: List[CVOutput],
        vacancy_text: str,
        show_progress: bool = True
    ) -> List[tuple[CVOutput, MatchAnalysis]]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è –æ–¥–Ω–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏
        
        Args:
            candidates: –°–ø–∏—Å–æ–∫ CV –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
            vacancy_text: –¢–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏
            show_progress: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø–∞—Ä (CV, MatchAnalysis)
        """
        results = []
        
        for i, cv in enumerate(candidates, 1):
            if show_progress:
                print(f"[{i}/{len(candidates)}] –ê–Ω–∞–ª–∏–∑: {cv.full_name}...")
            
            try:
                analysis = self.analyze_match(cv, vacancy_text)
                results.append((cv, analysis))
                
                if show_progress:
                    print(f"   ‚úÖ Score: {analysis.relevance_score:.3f} - {analysis.recommendation}")
            except Exception as e:
                if show_progress:
                    print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")
                continue
        
        return results
    
    def _format_work_history(self, work_history: List) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–±–æ—Ç—ã –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞"""
        if not work_history:
            return "No work history provided"
        
        formatted = []
        for i, work in enumerate(work_history[:5], 1):  # –¢–æ–ø-5 –ø–æ–∑–∏—Ü–∏–π
            formatted.append(
                f"{i}. {work.role} at {work.company} ({work.start_date} - {work.end_date})\n"
                f"   Technologies: {', '.join(work.technologies[:10]) if work.technologies else 'N/A'}\n"
                f"   {work.description[:200]}..."
            )
        
        return "\n".join(formatted)
    
    def _format_education(self, education: List) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞"""
        if not education:
            return "No education provided"
        
        formatted = [
            f"- {edu.degree} from {edu.institution} ({edu.year})"
            for edu in education
        ]
        
        return "\n".join(formatted)
    
    def get_score_interpretation(self, score: float) -> dict:
        """
        –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —á–∏—Å–ª–æ–≤–æ–≥–æ score
        
        Args:
            score: –û—Ü–µ–Ω–∫–∞ –æ—Ç 0.0 –¥–æ 1.0
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–µ–π
        """
        if score >= 0.9:
            return {
                "level": "exceptional",
                "label": "üåü –ò—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ",
                "description": "–ö–∞–Ω–¥–∏–¥–∞—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è",
                "color": "green"
            }
        elif score >= 0.75:
            return {
                "level": "strong",
                "label": "‚úÖ –°–∏–ª—å–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ",
                "description": "–ö–∞–Ω–¥–∏–¥–∞—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –±–æ–ª—å—à–∏–Ω—Å—Ç–≤—É —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π",
                "color": "lightgreen"
            }
        elif score >= 0.6:
            return {
                "level": "good",
                "label": "üëç –•–æ—Ä–æ—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ",
                "description": "–ö–∞–Ω–¥–∏–¥–∞—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º",
                "color": "blue"
            }
        elif score >= 0.4:
            return {
                "level": "moderate",
                "label": "‚ö†Ô∏è –£–º–µ—Ä–µ–Ω–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ",
                "description": "–ï—Å—Ç—å –ø—Ä–æ–±–µ–ª—ã –≤ –∫–ª—é—á–µ–≤—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è—Ö",
                "color": "orange"
            }
        elif score >= 0.2:
            return {
                "level": "weak",
                "label": "‚ùå –°–ª–∞–±–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ",
                "description": "–ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏",
                "color": "red"
            }
        else:
            return {
                "level": "poor",
                "label": "üö´ –ü–ª–æ—Ö–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ",
                "description": "–ö–∞–Ω–¥–∏–¥–∞—Ç –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —ç—Ç–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏",
                "color": "darkred"
            }


# ==================== –¢–ï–°–¢–û–í–´–ï –§–£–ù–ö–¶–ò–ò ====================

def test_analyzer_with_sample_data():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ"""
    from app.models.cv import WorkExperience, Education
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π CV
    sample_cv = CVOutput(
        full_name="–ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤",
        email="ivan@example.com",
        phone="+7 900 123-45-67",
        location=["–ú–æ—Å–∫–≤–∞, –†–æ—Å—Å–∏—è"],
        summary="Senior Python —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ —Å 5+ –≥–æ–¥–∞–º–∏ –æ–ø—ã—Ç–∞ –≤ backend —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ. "
                "–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Å—å –Ω–∞ FastAPI, Django, PostgreSQL. –û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã —Å Docker, "
                "Kubernetes, CI/CD. –£—á–∞—Å—Ç–≤–æ–≤–∞–ª –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –≤—ã—Å–æ–∫–æ–Ω–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º.",
        total_experience_months=60,
        work_history=[
            WorkExperience(
                role="Senior Python Developer",
                company="Tech Corp",
                start_date="2021-03",
                end_date="Present",
                description="–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–∞ FastAPI. "
                           "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ë–î. –í–Ω–µ–¥—Ä–µ–Ω–∏–µ CI/CD.",
                technologies=["Python", "FastAPI", "PostgreSQL", "Docker", "Redis", "Celery"]
            ),
            WorkExperience(
                role="Python Developer",
                company="StartupXYZ",
                start_date="2019-01",
                end_date="2021-02",
                description="Backend —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ Django. REST API, –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –≤–Ω–µ—à–Ω–∏–º–∏ —Å–µ—Ä–≤–∏—Å–∞–º–∏.",
                technologies=["Python", "Django", "MySQL", "RabbitMQ"]
            )
        ],
        education=[
            Education(
                institution="–ú–ì–£",
                degree="–ë–∞–∫–∞–ª–∞–≤—Ä, –ü—Ä–∏–∫–ª–∞–¥–Ω–∞—è –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞",
                year="2018"
            )
        ],
        skills=[
            "Python", "FastAPI", "Django", "PostgreSQL", "MySQL", "Docker",
            "Kubernetes", "Redis", "Celery", "RabbitMQ", "Git", "Linux"
        ],
        languages=["–†—É—Å—Å–∫–∏–π (—Ä–æ–¥–Ω–æ–π)", "–ê–Ω–≥–ª–∏–π—Å–∫–∏–π (Upper-Intermediate)"]
    )
    
    # –¢–µ—Å—Ç–æ–≤–∞—è –≤–∞–∫–∞–Ω—Å–∏—è
    vacancy = """
Senior Python Backend Developer

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã —Å Python –æ—Ç 3 –ª–µ—Ç
- –ó–Ω–∞–Ω–∏–µ FastAPI –∏–ª–∏ Django
- –û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã —Å PostgreSQL
- –ü–æ–Ω–∏–º–∞–Ω–∏–µ Docker –∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏–∏
- –û–ø—ã—Ç —Å Redis, Celery
- –ó–Ω–∞–Ω–∏–µ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ —á—Ç–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

–û–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏:
- –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∞ backend –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–≤
- –ü—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ API
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- Code review, –º–µ–Ω—Ç–æ—Ä–∏–Ω–≥ junior —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤

–ë—É–¥–µ—Ç –ø–ª—é—Å–æ–º:
- –û–ø—ã—Ç —Å Kubernetes
- –ó–Ω–∞–Ω–∏–µ GraphQL
- –û–ø—ã—Ç —Å ML/AI
"""
    
    print("="*70)
    print("–¢–ï–°–¢ LLM ANALYZER")
    print("="*70)
    
    print(f"\nüìã –ö–∞–Ω–¥–∏–¥–∞—Ç: {sample_cv.full_name}")
    print(f"üíº –û–ø—ã—Ç: {sample_cv.total_experience_months} –º–µ—Å. ({sample_cv.total_experience_months/12:.1f} –ª–µ—Ç)")
    print(f"üîß –ù–∞–≤—ã–∫–∏: {', '.join(sample_cv.skills[:5])}...")
    
    print(f"\nüìÑ –í–∞–∫–∞–Ω—Å–∏—è: Senior Python Backend Developer")
    print("="*70)
    
    # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
    analyzer = LLMAnalyzer(model="gpt-4o", temperature=0.3)
    
    print("\nü§ñ –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ LLM...")
    analysis = analyzer.analyze_match(sample_cv, vacancy)
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n" + "="*70)
    print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê")
    print("="*70)
    
    interpretation = analyzer.get_score_interpretation(analysis.relevance_score)
    
    print(f"\nüìä –û–¶–ï–ù–ö–ê: {analysis.relevance_score:.3f} / 1.0")
    print(f"   {interpretation['label']}")
    print(f"   {interpretation['description']}")
    
    print(f"\nüéØ –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: {analysis.overall_assessment.upper()}")
    print(f"üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {analysis.recommendation.upper()}")
    
    print(f"\nüìù –†–µ–∑—é–º–µ:")
    print(f"   {analysis.summary}")
    
    print(f"\n‚úÖ –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:")
    for i, strength in enumerate(analysis.strengths, 1):
        print(f"   {i}. {strength}")
    
    print(f"\n‚ö†Ô∏è  –°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:")
    for i, weakness in enumerate(analysis.weaknesses, 1):
        print(f"   {i}. {weakness}")
    
    print(f"\nüéØ –ö–ª—é—á–µ–≤—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è:")
    for i, match in enumerate(analysis.key_matches, 1):
        print(f"   {i}. {match}")
    
    print(f"\n‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:")
    for i, missing in enumerate(analysis.missing_requirements, 1):
        print(f"   {i}. {missing}")
    
    print(f"\nüí≠ –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:")
    print(f"   {analysis.reasoning}")
    
    print("\n" + "="*70)
    print("‚úÖ –¢–ï–°–¢ –ó–ê–í–ï–†–®–ï–ù")
    print("="*70)
    
    return analysis


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞
    test_analyzer_with_sample_data()
