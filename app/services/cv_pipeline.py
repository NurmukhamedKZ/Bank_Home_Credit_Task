"""
CVPipeline - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—é–º–µ.

–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª:
    Email ‚Üí –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ —Ç–∏–ø—É ‚Üí –ü–∞—Ä—Å–∏–Ω–≥ ‚Üí –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ ‚Üí JSON ‚Üí Qdrant (BM25)

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    pipeline = CVPipeline()
    pipeline.process_file("/path/to/resume.pdf")   # –û–¥–∏–Ω —Ñ–∞–π–ª
    pipeline.run_email_watcher(interval=60)         # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–æ—á—Ç—ã
"""

import time
import shutil
import traceback
from pathlib import Path
from typing import List, Dict, Optional
from datetime import datetime

from app.services.cv_parser import CVParser
from app.services.email_fetcher import EmailFetcher
from app.core.config import QDRANT_COLLECTION_NAME


class CVPipeline:
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—é–º–µ –æ—Ç –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≤ Qdrant.
    
    –≠—Ç–∞–ø—ã:
        1. –ü–æ–ª—É—á–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ (–∏–∑ email –∏–ª–∏ –≤—Ä—É—á–Ω—É—é)
        2. –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–∏–ø—É (PDF ‚Üí PDF_CVs, DOCX ‚Üí DOCX_CVs, TXT ‚Üí Parsed_CVs)
        3. –ü–∞—Ä—Å–∏–Ω–≥ –≤ —Ç–µ–∫—Å—Ç (PDF/DOCX ‚Üí —Ç–µ–∫—Å—Ç)
        4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ Parsed_CVs
        5. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ LLM ‚Üí CVOutput
        6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON –≤ CV_JSONs
        7. –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (dense + BM25)
        8. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Qdrant
    """
    
    def __init__(
        self,
        collection_name: str = None,
        sparse_method: str = "bm25"
    ):
        """
        Args:
            collection_name: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –≤ Qdrant
            sparse_method: –ú–µ—Ç–æ–¥ sparse embeddings ("bm25" –∏–ª–∏ "tfidf")
        """
        self.collection_name = collection_name or QDRANT_COLLECTION_NAME
        self.sparse_method = sparse_method
        
        # –ü—É—Ç–∏ –∫ –ø–∞–ø–∫–∞–º
        self.project_root = Path(__file__).parent.parent.parent
        self.pdf_cvs_folder = self.project_root / "data" / "PDF_CVs"
        self.docx_cvs_folder = self.project_root / "data" / "DOCX_CVs"
        self.parsed_cvs_folder = self.project_root / "data" / "Parsed_CVs"
        self.json_cvs_folder = self.project_root / "data" / "CV_JSONs"
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏
        for folder in [self.pdf_cvs_folder, self.docx_cvs_folder, self.parsed_cvs_folder, self.json_cvs_folder]:
            folder.mkdir(parents=True, exist_ok=True)
        
        # CVParser –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ Qdrant
        print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CVPipeline...")
        self.parser = CVParser(
            collection_name=collection_name,
            sparse_method=sparse_method
        )
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            "processed": 0,
            "failed": 0,
            "skipped": 0
        }
        
        print(f"üìÅ PDF_CVs: {self.pdf_cvs_folder}")
        print(f"üìÅ DOCX_CVs: {self.docx_cvs_folder}")
        print(f"üìÅ Parsed_CVs: {self.parsed_cvs_folder}")
        print(f"üìÅ CV_JSONs: {self.json_cvs_folder}")
        print(f"‚úÖ CVPipeline –≥–æ—Ç–æ–≤ (–∫–æ–ª–ª–µ–∫—Ü–∏—è: {collection_name}, –º–µ—Ç–æ–¥: {sparse_method})\n")
    
    def _get_existing_source_files(self) -> set:
        """–ü–æ–ª—É—á–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ source_file –∏–∑ Qdrant –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
        try:
            scroll_result = self.parser.qdrant_client.scroll(
                collection_name=self.collection_name,
                limit=10000,
                with_payload=True,
                with_vectors=False
            )
            return {
                point.payload.get("source_file", "")
                for point in scroll_result[0]
                if point.payload.get("source_file")
            }
        except Exception:
            return set()
    
    def _sort_file(self, file_path: Path) -> Path:
        """
        –°–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ñ–∞–π–ª –ø–æ —Ç–∏–ø—É –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –ø–∞–ø–∫—É.
        
        Args:
            file_path: –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
            
        Returns:
            –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤ –Ω–æ–≤–æ–π –ø–∞–ø–∫–µ
        """
        ext = file_path.suffix.lower()
        
        if ext == ".pdf":
            target_folder = self.pdf_cvs_folder
        elif ext in [".docx", ".doc"]:
            target_folder = self.docx_cvs_folder
        elif ext == ".txt":
            target_folder = self.parsed_cvs_folder
        else:
            # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –µ—Å—Ç—å –≤ Raw_CVs
            target_folder = self.project_root / "data" / "Raw_CVs"
            target_folder.mkdir(parents=True, exist_ok=True)
        
        target_path = target_folder / file_path.name
        
        # –ï—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ –≤ –Ω—É–∂–Ω–æ–π –ø–∞–ø–∫–µ ‚Äî –Ω–µ –∫–æ–ø–∏—Ä—É–µ–º
        if file_path.resolve() == target_path.resolve():
            return target_path
        
        # –ï—Å–ª–∏ —Ñ–∞–π–ª —Å —Ç–∞–∫–∏–º –∏–º–µ–Ω–µ–º —É–∂–µ –µ—Å—Ç—å ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º timestamp
        if target_path.exists():
            stem = file_path.stem
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            target_path = target_folder / f"{stem}_{timestamp}{ext}"
        
        shutil.copy2(file_path, target_path)
        print(f"   üìÇ –°–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {target_folder.name}/{target_path.name}")
        
        return target_path
    
    def _parse_to_text(self, file_path: Path) -> str:
        """
        –ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª –≤ —Ç–µ–∫—Å—Ç. PDF/DOCX —á–µ—Ä–µ–∑ LlamaParse, TXT –Ω–∞–ø—Ä—è–º—É—é.
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            
        Returns:
            –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        ext = file_path.suffix.lower()
        
        if ext == ".txt":
            return file_path.read_text(encoding="utf-8")
        elif ext == ".pdf":
            return self.parser.parse_pdf(file_path)
        elif ext in [".docx", ".doc"]:
            return self.parser.parse_file(file_path)
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {ext}")
    
    def process_file(self, file_path: str | Path, skip_existing: bool = True) -> Optional[Dict]:
        """
        –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞.
        
        –≠—Ç–∞–ø—ã:
            1. –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–∏–ø—É (PDF/DOCX/TXT ‚Üí —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∞—è –ø–∞–ø–∫–∞)
            2. –ü–∞—Ä—Å–∏–Ω–≥ –≤ —Ç–µ–∫—Å—Ç
            3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ Parsed_CVs
            4. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ LLM ‚Üí CVOutput
            5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON –≤ CV_JSONs
            6. –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ (dense + BM25)
            7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Qdrant
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Ä–µ–∑—é–º–µ
            skip_existing: –ü—Ä–æ–ø—É—Å–∫–∞—Ç—å —Ñ–∞–π–ª—ã —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –≤ Qdrant
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–ª–∏ None –µ—Å–ª–∏ –æ—à–∏–±–∫–∞
        """
        file_path = Path(file_path)
        
        if not file_path.exists():
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            return None
        
        print(f"\n{'='*60}")
        print(f"üöÄ –û–±—Ä–∞–±–æ—Ç–∫–∞: {file_path.name}")
        print(f"{'='*60}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        if skip_existing:
            existing = self._get_existing_source_files()
            if file_path.stem in existing:
                print(f"   ‚è≠Ô∏è  –£–∂–µ –≤ Qdrant, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                self.stats["skipped"] += 1
                return None
        
        try:
            # 1. –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–∏–ø—É
            print("   üìÇ –®–∞–≥ 1: –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–∏–ø—É...")
            sorted_path = self._sort_file(file_path)
            
            # 2. –ü–∞—Ä—Å–∏–Ω–≥ –≤ —Ç–µ–∫—Å—Ç
            print("   üìÑ –®–∞–≥ 2: –ü–∞—Ä—Å–∏–Ω–≥ –≤ —Ç–µ–∫—Å—Ç...")
            full_text = self._parse_to_text(sorted_path)
            
            if not full_text or not full_text.strip():
                print("   ‚ö†Ô∏è  –ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                self.stats["failed"] += 1
                return None
            
            print(f"      ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ Parsed_CVs
            parsed_txt_path = self.parsed_cvs_folder / f"{file_path.stem}.txt"
            if not parsed_txt_path.exists() or sorted_path.suffix.lower() != ".txt":
                parsed_txt_path.write_text(full_text, encoding="utf-8")
                print(f"   üíæ –®–∞–≥ 3: –¢–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω ‚Üí Parsed_CVs/{parsed_txt_path.name}")
            else:
                print(f"   üíæ –®–∞–≥ 3: –¢–µ–∫—Å—Ç —É–∂–µ –≤ Parsed_CVs")
            
            # 4. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ LLM
            print("   ü§ñ –®–∞–≥ 4: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (LLM)...")
            cv_data = self.parser.extract_cv_data(full_text)
            print(f"      ‚úÖ {cv_data.full_name} | {cv_data.total_experience_months} –º–µ—Å. | {len(cv_data.skills)} –Ω–∞–≤—ã–∫–æ–≤")
            
            # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON
            print("   üìã –®–∞–≥ 5: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON...")
            json_path = self.parser.save_json(cv_data, file_path.name)
            print(f"      ‚úÖ ‚Üí CV_JSONs/{json_path.name}")
            
            # 6. –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            print(f"   üî¢ –®–∞–≥ 6: –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ ({self.sparse_method.upper()})...")
            searchable_text = self.parser.create_searchable_text(cv_data)
            dense_vector, sparse_indices, sparse_values = self.parser.create_embeddings(searchable_text)
            print(f"      ‚úÖ Dense: {len(dense_vector)} dims, Sparse: {len(sparse_indices)} non-zero")
            
            # 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Qdrant
            print("   ‚òÅÔ∏è  –®–∞–≥ 7: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Qdrant...")
            point_id = self.parser.save_to_qdrant(
                cv_data=cv_data,
                full_text=full_text,
                dense_vector=dense_vector,
                sparse_indices=sparse_indices,
                sparse_values=sparse_values,
                source_file=file_path.stem
            )
            
            self.stats["processed"] += 1
            
            print(f"\n   ‚úÖ –ì–û–¢–û–í–û: {cv_data.full_name}")
            print(f"      Qdrant ID: {point_id}")
            print(f"{'='*60}\n")
            
            return {
                "file": file_path.name,
                "point_id": point_id,
                "full_name": cv_data.full_name,
                "email": cv_data.email,
                "experience_months": cv_data.total_experience_months,
                "skills_count": len(cv_data.skills),
                "json_file": str(json_path),
                "parsed_text": str(parsed_txt_path)
            }
        
        except Exception as e:
            print(f"\n   ‚ùå –û–®–ò–ë–ö–ê: {e}")
            traceback.print_exc()
            self.stats["failed"] += 1
            return None
    
    def process_files(self, file_paths: List[Path], skip_existing: bool = True) -> List[Dict]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤.
        
        Args:
            file_paths: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º
            skip_existing: –ü—Ä–æ–ø—É—Å–∫–∞—Ç—å —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        results = []
        total = len(file_paths)
        
        print(f"\nüì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ {total} —Ñ–∞–π–ª–æ–≤...\n")
        
        for i, fp in enumerate(file_paths, 1):
            print(f"[{i}/{total}]", end="")
            result = self.process_file(fp, skip_existing=skip_existing)
            if result:
                results.append(result)
        
        # –ü–µ—Ä–µ–æ–±—É—á–∞–µ–º sparse –º–æ–¥–µ–ª—å –Ω–∞ –ø–æ–ª–Ω–æ–º –∫–æ—Ä–ø—É—Å–µ
        if results:
            print(f"\nüîÑ –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ {self.sparse_method.upper()} –Ω–∞ –≤—Å—ë–º –∫–æ—Ä–ø—É—Å–µ...")
            self.parser.refit_sparse()
        
        self._print_stats()
        return results
    
    def process_from_email(
        self,
        folder: str = "INBOX",
        search_criteria: str = "UNSEEN",
        mark_as_read: bool = True
    ) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–∑—é–º–µ –∏–∑ email –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏—Ö —á–µ—Ä–µ–∑ –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω.
        
        Args:
            folder: –ü–∞–ø–∫–∞ –ø–æ—á—Ç—ã
            search_criteria: –ö—Ä–∏—Ç–µ—Ä–∏–π –ø–æ–∏—Å–∫–∞
            mark_as_read: –ü–æ–º–µ—á–∞—Ç—å –∫–∞–∫ –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω–æ–µ
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        print(f"\n{'='*60}")
        print("üìß –ü–û–õ–£–ß–ï–ù–ò–ï –†–ï–ó–Æ–ú–ï –ò–ó –ü–û–ß–¢–´")
        print(f"{'='*60}\n")
        
        # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª—ã –∏–∑ –ø–æ—á—Ç—ã
        with EmailFetcher() as fetcher:
            saved_files = fetcher.fetch_resumes(
                folder=folder,
                search_criteria=search_criteria,
                save_text_body=True,
                mark_as_read=mark_as_read
            )
        
        if not saved_files:
            print("\nüì≠ –ù–æ–≤—ã—Ö —Ä–µ–∑—é–º–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            return []
        
        print(f"\nüì¨ –ü–æ–ª—É—á–µ–Ω–æ {len(saved_files)} —Ñ–∞–π–ª–æ–≤ –∏–∑ –ø–æ—á—Ç—ã")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª —á–µ—Ä–µ–∑ –ø–∞–π–ø–ª–∞–π–Ω
        file_paths = [Path(f) for f in saved_files]
        return self.process_files(file_paths)
    
    def run_email_watcher(
        self,
        interval: int = 60,
        folder: str = "INBOX",
        mark_as_read: bool = True
    ):
        """
        –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–æ—á—Ç—ã. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–æ–≤—ã–µ –ø–∏—Å—å–º–∞ –∫–∞–∂–¥—ã–µ N —Å–µ–∫—É–Ω–¥.
        
        Args:
            interval: –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (default: 60)
            folder: –ü–∞–ø–∫–∞ –ø–æ—á—Ç—ã
            mark_as_read: –ü–æ–º–µ—á–∞—Ç—å –∫–∞–∫ –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω–æ–µ
        """
        print(f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë         –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –ú–û–ù–ò–¢–û–†–ò–ù–ì –ü–û–ß–¢–´                       ‚ïë
‚ïë  –ò–Ω—Ç–µ—Ä–≤–∞–ª: {interval:>3} —Å–µ–∫ | –ü–∞–ø–∫–∞: {folder:<10}                        ‚ïë
‚ïë  –ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏                                 ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
        """)
        
        cycle = 0
        
        try:
            while True:
                cycle += 1
                now = datetime.now().strftime("%H:%M:%S")
                print(f"\n[{now}] üîÑ –ü—Ä–æ–≤–µ—Ä–∫–∞ #{cycle}...")
                
                try:
                    results = self.process_from_email(
                        folder=folder,
                        search_criteria="UNSEEN",
                        mark_as_read=mark_as_read
                    )
                    
                    if results:
                        print(f"[{now}] ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(results)} –Ω–æ–≤—ã—Ö —Ä–µ–∑—é–º–µ")
                    else:
                        print(f"[{now}] üì≠ –ù–æ–≤—ã—Ö —Ä–µ–∑—é–º–µ –Ω–µ—Ç")
                
                except Exception as e:
                    print(f"[{now}] ‚ö†Ô∏è  –û—à–∏–±–∫–∞: {e}")
                
                print(f"[{now}] üí§ –°–ª–µ–¥—É—é—â–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ {interval} —Å–µ–∫...")
                time.sleep(interval)
        
        except KeyboardInterrupt:
            print(f"\n\n{'='*60}")
            print("üõë –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            self._print_stats()
            print(f"{'='*60}\n")
    
    def _print_stats(self):
        """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        print(f"\n{'='*60}")
        print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–ê–ô–ü–õ–ê–ô–ù–ê")
        print(f"{'='*60}")
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.stats['processed']}")
        print(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ: {self.stats['skipped']}")
        print(f"‚ùå –û—à–∏–±–æ–∫: {self.stats['failed']}")
        print(f"{'='*60}")
