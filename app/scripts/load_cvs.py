#!/usr/bin/env python3
"""
Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° CV Ğ² Qdrant.

Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:
    python -m app.scripts.load_cvs           # TXT Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ñ TF-IDF
    python -m app.scripts.load_cvs --bm25    # TXT Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ñ BM25
    python -m app.scripts.load_cvs --pdf     # PDF Ñ„Ğ°Ğ¹Ğ»Ñ‹
"""

import sys
from pathlib import Path


def process_txt_cvs(
    txt_folder: Path,
    collection_name: str = "CVs",
    skip_existing: bool = False,
    sparse_method: str = "tfidf"
) -> dict:
    """ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ TXT Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ² Qdrant"""
    from app.services.cv_parser import CVParser
    
    if not txt_folder.exists():
        raise FileNotFoundError(f"ĞŸĞ°Ğ¿ĞºĞ° Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°: {txt_folder}")
    
    print(f"ğŸš€ Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ CVParser (ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ: {collection_name}, Ğ¼ĞµÑ‚Ğ¾Ğ´: {sparse_method})")
    parser = CVParser(collection_name=collection_name, sparse_method=sparse_method)
    
    txt_files = list(txt_folder.glob("*.txt"))
    
    if not txt_files:
        print(f"âš ï¸  TXT Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹ Ğ² {txt_folder}")
        return {"success": 0, "failed": 0, "skipped": 0, "results": []}
    
    print(f"ğŸ“ ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ TXT Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²: {len(txt_files)}\n")
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ ÑĞ¿Ğ¸ÑĞ¾Ğº ÑƒĞ¶Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ñ… CV
    existing_names = set()
    if skip_existing:
        try:
            scroll_result = parser.qdrant_client.scroll(
                collection_name=collection_name,
                limit=1000,
                with_payload=True,
                with_vectors=False
            )
            existing_names = {
                point.payload.get('full_name', '') 
                for point in scroll_result[0]
            }
            print(f"â„¹ï¸  Ğ£Ğ¶Ğµ Ğ² Qdrant: {len(existing_names)} CV\n")
        except Exception as e:
            print(f"âš ï¸  ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¸Ğ· Qdrant: {e}\n")
    
    results = []
    failed = []
    skipped = []
    
    for i, txt_file in enumerate(txt_files, 1):
        print(f"\n{'='*60}")
        print(f"[{i}/{len(txt_files)}] ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°: {txt_file.name}")
        print(f"{'='*60}")
        
        try:
            print("ğŸ“„ Ğ§Ñ‚ĞµĞ½Ğ¸Ğµ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ¸Ğ· Ñ„Ğ°Ğ¹Ğ»Ğ°...")
            full_text = txt_file.read_text(encoding='utf-8')
            
            if not full_text.strip():
                print(f"âš ï¸  Ğ¤Ğ°Ğ¹Ğ» Ğ¿ÑƒÑÑ‚, Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼")
                skipped.append({"file": txt_file.name, "reason": "empty_file"})
                continue
            
            print(f"   âœ… ĞŸÑ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ğ½Ğ¾ {len(full_text)} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²")
            
            print("ğŸ¤– Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…...")
            cv_data = parser.extract_cv_data(full_text)
            print(f"   âœ… {cv_data.full_name}")
            
            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ JSON Ñ Ñ‚ĞµĞ¼ Ğ¶Ğµ Ğ¸Ğ¼ĞµĞ½ĞµĞ¼ Ñ‡Ñ‚Ğ¾ Ğ¸ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ»
            print("ğŸ“‹ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ JSON...")
            json_file = parser.save_json(cv_data, txt_file.name)
            print(f"   âœ… {json_file.name}")
            
            if skip_existing and cv_data.full_name in existing_names:
                print(f"   â­ï¸  CV ÑƒĞ¶Ğµ Ğ² Qdrant, Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼")
                skipped.append({
                    "file": txt_file.name,
                    "full_name": cv_data.full_name,
                    "reason": "already_exists"
                })
                continue
            
            print("ğŸ” Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ°...")
            searchable_text = parser.create_searchable_text(cv_data)
            
            print("ğŸ”¢ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ²...")
            dense_vector, sparse_indices, sparse_values = parser.create_embeddings(searchable_text)
            
            print("ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ² Qdrant...")
            point_id = parser.save_to_qdrant(
                cv_data=cv_data,
                full_text=full_text,
                dense_vector=dense_vector,
                sparse_indices=sparse_indices,
                sparse_values=sparse_values,
                source_file=txt_file.stem
            )
            
            results.append({
                "file": txt_file.name,
                "status": "success",
                "point_id": point_id,
                "full_name": cv_data.full_name,
                "email": cv_data.email,
                "experience_months": cv_data.total_experience_months,
                "skills_count": len(cv_data.skills),
                "json_file": str(json_file)
            })
            
            print(f"\nâœ… Ğ£ÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾: {cv_data.full_name}")
            
        except Exception as e:
            print(f"\nâŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ {txt_file.name}: {e}")
            import traceback
            traceback.print_exc()
            failed.append({
                "file": txt_file.name,
                "status": "failed",
                "error": str(e)
            })
            continue
    
    # ĞŸĞµÑ€ĞµĞ¾Ğ±ÑƒÑ‡Ğ°ĞµĞ¼ sparse Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
    if len(results) > 0:
        print(f"\n{'='*60}")
        print(f"ğŸ”„ ĞŸĞµÑ€ĞµĞ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ {parser.sparse_method.upper()} Ğ½Ğ° Ğ²ÑĞµĞ¼ ĞºĞ¾Ñ€Ğ¿ÑƒÑĞµ...")
        parser.refit_sparse()
    
    # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
    print(f"\n{'='*60}")
    print("ğŸ“Š Ğ˜Ğ¢ĞĞ“ĞĞ’ĞĞ¯ Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ")
    print(f"{'='*60}")
    print(f"âœ… Ğ£ÑĞ¿ĞµÑˆĞ½Ğ¾: {len(results)}")
    print(f"â­ï¸  ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾: {len(skipped)}")
    print(f"âŒ ĞÑˆĞ¸Ğ±Ğ¾Ğº: {len(failed)}")
    
    return {
        "success": len(results),
        "failed": len(failed),
        "skipped": len(skipped),
        "total": len(txt_files),
        "results": results,
        "errors": failed
    }


def main():
    """ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° CV Ğ² Qdrant")
    parser.add_argument("--tfidf", action="store_true", help="Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ TF-IDF Ğ²Ğ¼ĞµÑÑ‚Ğ¾ BM25")
    parser.add_argument("--pdf", action="store_true", help="ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ PDF Ñ„Ğ°Ğ¹Ğ»Ñ‹")
    parser.add_argument("--skip-existing", action="store_true", default=True, help="ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°Ñ‚ÑŒ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ CV")
    parser.add_argument("--no-skip", action="store_true", help="ĞĞµ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°Ñ‚ÑŒ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ CV")
    
    args = parser.parse_args()
    
    project_root = Path(__file__).parent.parent.parent
    sparse_method = "tfidf" if args.tfidf else None  # None = Ğ´ĞµÑ„Ğ¾Ğ»Ñ‚ BM25 Ğ¸Ğ· ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ°
    skip_existing = not args.no_skip
    
    from app.core.config import DEFAULT_SPARSE_METHOD
    display_method = sparse_method or DEFAULT_SPARSE_METHOD
    
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ CV Ğ’ QDRANT                                  â•‘
â•‘  Sparse Ğ¼ĞµÑ‚Ğ¾Ğ´: {display_method.upper():<10}                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    if args.pdf:
        cvs_folder = project_root / "data" / "PDF_CVs"
        print(f"ğŸ“ ĞŸĞ°Ğ¿ĞºĞ° Ñ PDF: {cvs_folder}")
        # TODO: Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ PDF
        print("âš ï¸  ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° PDF Ğ¿Ğ¾ĞºĞ° Ğ½Ğµ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ° Ğ² ÑÑ‚Ğ¾Ğ¼ ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğµ")
    else:
        parsed_cvs_folder = project_root / "data" / "Parsed_CVs"
        print(f"ğŸ“ ĞŸĞ°Ğ¿ĞºĞ° Ñ TXT: {parsed_cvs_folder}")
        
        from app.core.config import QDRANT_COLLECTION_NAME
        
        summary = process_txt_cvs(
            txt_folder=parsed_cvs_folder,
            collection_name=QDRANT_COLLECTION_NAME,
            skip_existing=skip_existing,
            sparse_method=sparse_method
        )
        
        print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Ğ£ÑĞ¿ĞµÑˆĞ½Ğ¾: {summary['success']}
â­ï¸  ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾: {summary['skipped']}
âŒ ĞÑˆĞ¸Ğ±Ğ¾Ğº: {summary['failed']}

ğŸ’¡ Ğ¢ĞµĞ¿ĞµÑ€ÑŒ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¾Ñ†ĞµĞ½ĞºÑƒ:
   python -m app.scripts.run_evaluation --hybrid
        """)


if __name__ == "__main__":
    main()
