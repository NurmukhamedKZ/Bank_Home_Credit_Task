{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "fb7eb319",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "LLAMA_PARSE_API = os.getenv(\"LLAMA_PARSE_API\")\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "d1ca1ac4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_parse import LlamaParse\n",
        "\n",
        "parser = LlamaParse(\n",
        "    api_key=LLAMA_PARSE_API,\n",
        "    parse_mode=\"parse_page_with_llm\",\n",
        "    result_type=\"markdown\",\n",
        "    high_res_ocr=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "314cc1f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.agents import create_agent\n",
        "from langchain_openai import ChatOpenAI, OpenAI\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    api_key=OPENAI_API_KEY\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "be8bafc4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Путь к файлу: /Users/nurma/vscode_projects/Bank_Home_Credit_Task/data/Әшекей Нұрмұхамед-5-1.pdf\n",
            "Файл существует: False\n",
            "Ошибка: файл не найден - /Users/nurma/vscode_projects/Bank_Home_Credit_Task/data/Әшекей Нұрмұхамед-5-1.pdf\n"
          ]
        }
      ],
      "source": [
        "# Вариант 6: Использование LlamaParse + LangChain\n",
        "from llama_parse import LlamaParse\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.documents import Document\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Получаем текущую директорию notebook и строим путь к data/\n",
        "notebook_dir = Path(os.getcwd())\n",
        "pdf_path = notebook_dir.parent / \"data\" / \"Әшекей Нұрмұхамед-5-1.pdf\"\n",
        "\n",
        "print(f\"Путь к файлу: {pdf_path}\")\n",
        "print(f\"Файл существует: {pdf_path.exists()}\")\n",
        "\n",
        "# Парсим PDF через LlamaParse (лучшее качество извлечения текста)\n",
        "if pdf_path.exists():\n",
        "    print(\"Парсинг PDF через LlamaParse...\")\n",
        "    parsed_documents = parser.load_data(str(pdf_path))  # Конвертируем Path в строку\n",
        "\n",
        "else:\n",
        "    print(f\"Ошибка: файл не найден - {pdf_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "d74275f6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id_='89bc9fa9-f735-4a90-ae31-cd09568c6872', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='\\n# Резюме\\n\\n# Әшекей Нұрмұхамед\\n\\nМужчина, 22 года, родился 30 апреля 2003\\n\\nКонтактная информация:\\n\\n- Телефон: +7 (701) 1187021 — предпочитаемый способ связи\\n- Github: https://github.com/NurmukhamedKZ\\n- LinkedIn: https://www.linkedin.com/in/nurmukhamed-ashekey-3031a3369/\\n- Telegram: @nureke3445\\n- Email: ashekeinureke@gmail.com\\n\\nПроживает: Алматы\\n\\nГражданство: Казахстан, есть разрешение на работу: Казахстан\\n\\nНе готов к переезду, готов к командировкам\\n\\n# Желаемая должность и зарплата\\n\\nAI-инженер\\n\\nСпециализации:\\n\\n- Дата-сайентист\\n- Программист, разработчик\\n\\nТип занятости: полная занятость, частичная занятость, проектная работа/разовое задание, стажировка\\n\\nФормат работы: на месте работодателя, гибрид, удалённо\\n\\nЖелательное время в пути до работы: не имеет значения\\n\\n# Опыт работы — 1 год 4 месяца\\n\\n# Сентябрь 2025 — настоящее время\\n\\n# Slideble (Slideshow generator) — AI Engineer\\n\\n6 месяцев\\n\\n- Сократил операционные расходы на генерацию слайд-шоу за счет оптимизации потребления токенов LLM на 30% через внедрение стратегий кэширования и продвинутого промпт-инжиниринга.\\n- Ускорил процесс отладки и итерации промптов на 40% и значительно повысил надежность системы инициировав и интегрировав пайплайнo bservability на базе LangSmith.\\n- Исключил 100% ошибок рендеринга сцен вызванных некорректными ответами моделей спроектировав архитектуру пайплайна структурированного вывода данных с жестким соблюдением JSON схем.\\n- Повысил фактологическую точность генерируемого контента проведя сравнительный анализ поисковых инструментов и интегрировав Tavily API для извлечения внешнего контекста.\\n\\nTech Stack: Python, OpenAI API, LangChain, LangGraph, LangSmith, PostgreSQL, SQLAlchemy, Tavily API, FastAPI\\n\\n# Ноябрь 2024 — Сентябрь 2025\\n\\n# JauapAI (Educational RAG Platform) — AI Engineer\\n\\n11 месяцев\\n\\n- Увеличил показатель удержания пользователей снизив время получения первого токена TTFT на 62% с 40 до 15 секунд через внедрение асинхронной обработки и тюнинг векторного поиска.\\n- Решил проблему точности поиска сложной академической терминологии внедрив Hybrid Search на базе Dense и Sparse эмбеддингов что позволило устранить критические.\\n\\nРезюме обновлено 2 февраля 2026 в 10:05\\n\\n\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
              " Document(id_='49d6620d-02bf-4ab5-b3ba-124e1f779f2d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='\\n\\n# галлюцинации модели.\\n\\nАвтоматизировал оцифровку сложных учебных материалов с формулами и таблицами разработав ETL пайплайн с использованием VLM воркфлоу и стратегий Semantic Chunking.\\n\\nОбеспечил высокую доступность системы и поддержку конкурентных сессий спроектировав масштабируемый бэкенд на FastAPI и Docker\\n\\n# Tech Stack:\\n\\nPython, FastAPI, Docker, LangChain, Qdrant (VectorDB), Redis, PostgreSQL, OpenAI API, Telegram API. ML Ops &#x26; Embeddings: Hybrid Search (BGE-M3, Gemini-001, Voyage-4).\\n\\n# Образование\\n\\n| Бакалавр | 2025 | Казахстанско-Британский технический университет, Алматы             |\\n| -------- | ---- | ------------------------------------------------------------------- |\\n| Бакалавр |      | Школа Информационных Технологий и Инженерии, Информационные системы |\\n\\n# Навыки\\n\\nЗнание языков:\\n\\n- Казахский — Родной\\n- Английский — C1 — Продвинутый\\n- Русский — C2 — В совершенстве\\n\\nНавыки:\\n\\n- Python\\n- SQL\\n- Английский язык\\n- PostgreSQL\\n- Git\\n- MySQL\\n- langchain\\n- NLP\\n- LLM\\n- PyTorch\\n- pandas\\n- Scikit-learn\\n- Docker\\n- FastAPI\\n- RAG\\n- ML\\n- MLflow\\n- AI agent\\n- Matplotlib\\n- Seaborn\\n- AI\\n- TensorFlow\\n- API\\n- Deep Learning\\n- AI engineer\\n- ChatGPT\\n- PROMT\\n- Numpy\\n\\n# Дополнительная информация\\n\\nОбо мне: Я AI инженер с фокусом на разработку масштабируемых RAG систем и автономных AI агентов которые решают реальные задачи бизнеса.\\n\\nTelegram: @Nureke3445\\n\\nӘшекей Нұрмұхамед • Резюме обновлено 2 февраля 2026 в 10:05\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parsed_documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "012d3da6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "# Резюме\n",
            "\n",
            "# Әшекей Нұрмұхамед\n",
            "\n",
            "Мужчина, 22 года, родился 30 апреля 2003\n",
            "\n",
            "Контактная информация:\n",
            "\n",
            "- Телефон: +7 (701) 1187021 — предпочитаемый способ связи\n",
            "- Github: https://github.com/NurmukhamedKZ\n",
            "- LinkedIn: https://www.linkedin.com/in/nurmukhamed-ashekey-3031a3369/\n",
            "- Telegram: @nureke3445\n",
            "- Email: ashekeinureke@gmail.com\n",
            "\n",
            "Проживает: Алматы\n",
            "\n",
            "Гражданство: Казахстан, есть разрешение на работу: Казахстан\n",
            "\n",
            "Не готов к переезду, готов к командировкам\n",
            "\n",
            "# Желаемая должность и зарплата\n",
            "\n",
            "AI-инженер\n",
            "\n",
            "Специализации:\n",
            "\n",
            "- Дата-сайентист\n",
            "- Программист, разработчик\n",
            "\n",
            "Тип занятости: полная занятость, частичная занятость, проектная работа/разовое задание, стажировка\n",
            "\n",
            "Формат работы: на месте работодателя, гибрид, удалённо\n",
            "\n",
            "Желательное время в пути до работы: не имеет значения\n",
            "\n",
            "# Опыт работы — 1 год 4 месяца\n",
            "\n",
            "# Сентябрь 2025 — настоящее время\n",
            "\n",
            "# Slideble (Slideshow generator) — AI Engineer\n",
            "\n",
            "6 месяцев\n",
            "\n",
            "- Сократил операционные расходы на генерацию слайд-шоу за счет оптимизации потребления токенов LLM на 30% через внедрение стратегий кэширования и продвинутого промпт-инжиниринга.\n",
            "- Ускорил процесс отладки и итерации промптов на 40% и значительно повысил надежность системы инициировав и интегрировав пайплайнo bservability на базе LangSmith.\n",
            "- Исключил 100% ошибок рендеринга сцен вызванных некорректными ответами моделей спроектировав архитектуру пайплайна структурированного вывода данных с жестким соблюдением JSON схем.\n",
            "- Повысил фактологическую точность генерируемого контента проведя сравнительный анализ поисковых инструментов и интегрировав Tavily API для извлечения внешнего контекста.\n",
            "\n",
            "Tech Stack: Python, OpenAI API, LangChain, LangGraph, LangSmith, PostgreSQL, SQLAlchemy, Tavily API, FastAPI\n",
            "\n",
            "# Ноябрь 2024 — Сентябрь 2025\n",
            "\n",
            "# JauapAI (Educational RAG Platform) — AI Engineer\n",
            "\n",
            "11 месяцев\n",
            "\n",
            "- Увеличил показатель удержания пользователей снизив время получения первого токена TTFT на 62% с 40 до 15 секунд через внедрение асинхронной обработки и тюнинг векторного поиска.\n",
            "- Решил проблему точности поиска сложной академической терминологии внедрив Hybrid Search на базе Dense и Sparse эмбеддингов что позволило устранить критические.\n",
            "\n",
            "Резюме обновлено 2 февраля 2026 в 10:05\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(parsed_documents[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "9fdb3d80",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "# Резюме\n",
            "\n",
            "# Әшекей Нұрмұхамед\n",
            "\n",
            "Мужчина, 22 года, родился 30 апреля 2003\n",
            "\n",
            "Контактная информация:\n",
            "\n",
            "- Телефон: +7 (701) 1187021 — предпочитаемый способ связи\n",
            "- Github: https://github.com/NurmukhamedKZ\n",
            "- LinkedIn: https://www.linkedin.com/in/nurmukhamed-ashekey-3031a3369/\n",
            "- Telegram: @nureke3445\n",
            "- Email: ashekeinureke@gmail.com\n",
            "\n",
            "Проживает: Алматы\n",
            "\n",
            "Гражданство: Казахстан, есть разрешение на работу: Казахстан\n",
            "\n",
            "Не готов к переезду, готов к командировкам\n",
            "\n",
            "# Желаемая должность и зарплата\n",
            "\n",
            "AI-инженер\n",
            "\n",
            "Специализации:\n",
            "\n",
            "- Дата-сайентист\n",
            "- Программист, разработчик\n",
            "\n",
            "Тип занятости: полная занятость, частичная занятость, проектная работа/разовое задание, стажировка\n",
            "\n",
            "Формат работы: на месте работодателя, гибрид, удалённо\n",
            "\n",
            "Желательное время в пути до работы: не имеет значения\n",
            "\n",
            "# Опыт работы — 1 год 4 месяца\n",
            "\n",
            "# Сентябрь 2025 — настоящее время\n",
            "\n",
            "# Slideble (Slideshow generator) — AI Engineer\n",
            "\n",
            "6 месяцев\n",
            "\n",
            "- Сократил операционные расходы на генерацию слайд-шоу за счет оптимизации потребления токенов LLM на 30% через внедрение стратегий кэширования и продвинутого промпт-инжиниринга.\n",
            "- Ускорил процесс отладки и итерации промптов на 40% и значительно повысил надежность системы инициировав и интегрировав пайплайнo bservability на базе LangSmith.\n",
            "- Исключил 100% ошибок рендеринга сцен вызванных некорректными ответами моделей спроектировав архитектуру пайплайна структурированного вывода данных с жестким соблюдением JSON схем.\n",
            "- Повысил фактологическую точность генерируемого контента проведя сравнительный анализ поисковых инструментов и интегрировав Tavily API для извлечения внешнего контекста.\n",
            "\n",
            "Tech Stack: Python, OpenAI API, LangChain, LangGraph, LangSmith, PostgreSQL, SQLAlchemy, Tavily API, FastAPI\n",
            "\n",
            "# Ноябрь 2024 — Сентябрь 2025\n",
            "\n",
            "# JauapAI (Educational RAG Platform) — AI Engineer\n",
            "\n",
            "11 месяцев\n",
            "\n",
            "- Увеличил показатель удержания пользователей снизив время получения первого токена TTFT на 62% с 40 до 15 секунд через внедрение асинхронной обработки и тюнинг векторного поиска.\n",
            "- Решил проблему точности поиска сложной академической терминологии внедрив Hybrid Search на базе Dense и Sparse эмбеддингов что позволило устранить критические.\n",
            "\n",
            "Резюме обновлено 2 февраля 2026 в 10:05\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "# галлюцинации модели.\n",
            "\n",
            "Автоматизировал оцифровку сложных учебных материалов с формулами и таблицами разработав ETL пайплайн с использованием VLM воркфлоу и стратегий Semantic Chunking.\n",
            "\n",
            "Обеспечил высокую доступность системы и поддержку конкурентных сессий спроектировав масштабируемый бэкенд на FastAPI и Docker\n",
            "\n",
            "# Tech Stack:\n",
            "\n",
            "Python, FastAPI, Docker, LangChain, Qdrant (VectorDB), Redis, PostgreSQL, OpenAI API, Telegram API. ML Ops &#x26; Embeddings: Hybrid Search (BGE-M3, Gemini-001, Voyage-4).\n",
            "\n",
            "# Образование\n",
            "\n",
            "| Бакалавр | 2025 | Казахстанско-Британский технический университет, Алматы             |\n",
            "| -------- | ---- | ------------------------------------------------------------------- |\n",
            "| Бакалавр |      | Школа Информационных Технологий и Инженерии, Информационные системы |\n",
            "\n",
            "# Навыки\n",
            "\n",
            "Знание языков:\n",
            "\n",
            "- Казахский — Родной\n",
            "- Английский — C1 — Продвинутый\n",
            "- Русский — C2 — В совершенстве\n",
            "\n",
            "Навыки:\n",
            "\n",
            "- Python\n",
            "- SQL\n",
            "- Английский язык\n",
            "- PostgreSQL\n",
            "- Git\n",
            "- MySQL\n",
            "- langchain\n",
            "- NLP\n",
            "- LLM\n",
            "- PyTorch\n",
            "- pandas\n",
            "- Scikit-learn\n",
            "- Docker\n",
            "- FastAPI\n",
            "- RAG\n",
            "- ML\n",
            "- MLflow\n",
            "- AI agent\n",
            "- Matplotlib\n",
            "- Seaborn\n",
            "- AI\n",
            "- TensorFlow\n",
            "- API\n",
            "- Deep Learning\n",
            "- AI engineer\n",
            "- ChatGPT\n",
            "- PROMT\n",
            "- Numpy\n",
            "\n",
            "# Дополнительная информация\n",
            "\n",
            "Обо мне: Я AI инженер с фокусом на разработку масштабируемых RAG систем и автономных AI агентов которые решают реальные задачи бизнеса.\n",
            "\n",
            "Telegram: @Nureke3445\n",
            "\n",
            "Әшекей Нұрмұхамед • Резюме обновлено 2 февраля 2026 в 10:05\n",
            "\n"
          ]
        }
      ],
      "source": [
        "full_cv = \"\"\n",
        "for doc in parsed_documents:\n",
        "    full_cv += doc.text\n",
        "\n",
        "print(full_cv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "bf50b7bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# 1. Структура для места работы\n",
        "class WorkExperience(BaseModel):\n",
        "    role: str = Field(description=\"Job title, e.g. 'Senior Python Developer'\")\n",
        "    company: str = Field(description=\"Company name\")\n",
        "    start_date: str = Field(description=\"Start date usually in YYYY-MM format\")\n",
        "    end_date: str = Field(description=\"End date in YYYY-MM format or 'Present'\")\n",
        "    description: str = Field(description=\"Short summary of responsibilities and achievements\")\n",
        "    technologies: List[str] = Field(description=\"Specific tools used in this role\")\n",
        "\n",
        "# 2. Структура для образования\n",
        "class Education(BaseModel):\n",
        "    institution: str\n",
        "    degree: str = Field(description=\"Degree, e.g. 'Bachelor in Computer Science'\")\n",
        "    year: str = Field(description=\"Year of graduation\")\n",
        "\n",
        "# 3. Основная модель\n",
        "class CVOutput(BaseModel):\n",
        "    full_name: str = Field(description=\"Candidate's full name\")\n",
        "    email: Optional[str] = Field(description=\"Email address\")\n",
        "    phone: Optional[str] = Field(description=\"Phone number\")\n",
        "    links: List[str] = Field(description=\"URLs to LinkedIn, GitHub, Portfolio\")\n",
        "    location: List[str] = Field(description=\"Location of the candidate\")\n",
        "    \n",
        "    summary: str = Field(description=\"A brief professional summary of the candidate\")\n",
        "    \n",
        "    total_experience_months: int = Field(description=\"Total work experience in months\")\n",
        "    \n",
        "    # Вложенные сложные структуры\n",
        "    work_history: List[WorkExperience] = Field(description=\"List of work experiences\")\n",
        "    education: List[Education]\n",
        "    \n",
        "    skills: List[str] = Field(description=\"List of technical/hard skills\")\n",
        "    languages: List[str] = Field(description=\"Languages spoken and proficiency level\")\n",
        "\n",
        "# Обновляем промпт\n",
        "system_prompt = \"\"\"\n",
        "You are an expert technical recruiter and CV parser.\n",
        "Your task is to extract structured data from the provided resume text.\n",
        "\n",
        "CRITICAL RULES:\n",
        "1. Be precise with dates and names.\n",
        "2. If a specific field is missing, leave it as None or an empty list.\n",
        "3. For 'work_history', try to split distinct roles even if they are in the same company.\n",
        "4. Extract ALL technical skills mentioned.\n",
        "5. In 'total_experience_months', calculate the sum of all work durations.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "f4427ae8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CVOutput(full_name='Әшекей Нұрмұхамед', email='ashekeinureke@gmail.com', phone='+7 (701) 1187021', links=['https://github.com/NurmukhamedKZ', 'https://www.linkedin.com/in/nurmukhamed-ashekey-3031a3369/', '@nureke3445'], location=['Алматы'], summary='Я AI инженер с фокусом на разработку масштабируемых RAG систем и автономных AI агентов которые решают реальные задачи бизнеса.', total_experience_months=16, work_history=[WorkExperience(role='AI Engineer', company='Slideble (Slideshow generator)', start_date='2025-09', end_date='Present', description='Сократил операционные расходы на генерацию слайд-шоу за счет оптимизации потребления токенов LLM на 30% через внедрение стратегий кэширования и продвинутого промпт-инжиниринга. Ускорил процесс отладки и итерации промптов на 40% и значительно повысил надежность системы инициировав и интегрировав пайплайнo bservability на базе LangSmith. Исключил 100% ошибок рендеринга сцен вызванных некорректными ответами моделей спроектировав архитектуру пайплайна структурированного вывода данных с жестким соблюдением JSON схем. Повысил фактологическую точность генерируемого контента проведя сравнительный анализ поисковых инструментов и интегрировав Tavily API для извлечения внешнего контекста.', technologies=['Python', 'OpenAI API', 'LangChain', 'LangGraph', 'LangSmith', 'PostgreSQL', 'SQLAlchemy', 'Tavily API', 'FastAPI']), WorkExperience(role='AI Engineer', company='JauapAI (Educational RAG Platform)', start_date='2024-11', end_date='2025-09', description='Увеличил показатель удержания пользователей снизив время получения первого токена TTFT на 62% с 40 до 15 секунд через внедрение асинхронной обработки и тюнинг векторного поиска. Решил проблему точности поиска сложной академической терминологии внедрив Hybrid Search на базе Dense и Sparse эмбеддингов что позволило устранить критические галлюцинации модели. Автоматизировал оцифровку сложных учебных материалов с формулами и таблицами разработав ETL пайплайн с использованием VLM воркфлоу и стратегий Semantic Chunking. Обеспечил высокую доступность системы и поддержку конкурентных сессий спроектировав масштабируемый бэкенд на FastAPI и Docker.', technologies=['Python', 'FastAPI', 'Docker', 'LangChain', 'Qdrant (VectorDB)', 'Redis', 'PostgreSQL', 'OpenAI API', 'Telegram API', 'Hybrid Search (BGE-M3, Gemini-001, Voyage-4)'])], education=[Education(institution='Казахстанско-Британский технический университет, Алматы', degree='Бакалавр', year='2025'), Education(institution='Школа Информационных Технологий и Инженерии', degree='Бакалавр', year='')], skills=['Python', 'SQL', 'PostgreSQL', 'Git', 'MySQL', 'langchain', 'NLP', 'LLM', 'PyTorch', 'pandas', 'Scikit-learn', 'Docker', 'FastAPI', 'RAG', 'ML', 'MLflow', 'AI agent', 'Matplotlib', 'Seaborn', 'AI', 'TensorFlow', 'API', 'Deep Learning', 'ChatGPT', 'PROMT', 'Numpy'], languages=['Казахский — Родной', 'Английский — C1 — Продвинутый', 'Русский — C2 — В совершенстве'])"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    api_key=OPENAI_API_KEY,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Создаем LLM со структурированным выводом\n",
        "structured_llm = llm.with_structured_output(CVOutput)\n",
        "\n",
        "# Создаем промпт\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt),\n",
        "    (\"user\", \"Resume:\\n\\n{text}\")\n",
        "])\n",
        "\n",
        "# Создаем цепочку\n",
        "chain = prompt | structured_llm\n",
        "\n",
        "# Анализируем CV\n",
        "response = chain.invoke({\n",
        "    \"text\": full_cv\n",
        "})\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "5fe52565",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CVOutput(full_name='Әшекей Нұрмұхамед', email='ashekeinureke@gmail.com', phone='+7 (701) 1187021', links=['https://github.com/NurmukhamedKZ', 'https://www.linkedin.com/in/nurmukhamed-ashekey-3031a3369/', '@nureke3445'], location=['Алматы'], summary='Я AI инженер с фокусом на разработку масштабируемых RAG систем и автономных AI агентов которые решают реальные задачи бизнеса.', total_experience_months=16, work_history=[WorkExperience(role='AI Engineer', company='Slideble (Slideshow generator)', start_date='2025-09', end_date='Present', description='Сократил операционные расходы на генерацию слайд-шоу за счет оптимизации потребления токенов LLM на 30% через внедрение стратегий кэширования и продвинутого промпт-инжиниринга. Ускорил процесс отладки и итерации промптов на 40% и значительно повысил надежность системы инициировав и интегрировав пайплайнo bservability на базе LangSmith. Исключил 100% ошибок рендеринга сцен вызванных некорректными ответами моделей спроектировав архитектуру пайплайна структурированного вывода данных с жестким соблюдением JSON схем. Повысил фактологическую точность генерируемого контента проведя сравнительный анализ поисковых инструментов и интегрировав Tavily API для извлечения внешнего контекста.', technologies=['Python', 'OpenAI API', 'LangChain', 'LangGraph', 'LangSmith', 'PostgreSQL', 'SQLAlchemy', 'Tavily API', 'FastAPI']), WorkExperience(role='AI Engineer', company='JauapAI (Educational RAG Platform)', start_date='2024-11', end_date='2025-09', description='Увеличил показатель удержания пользователей снизив время получения первого токена TTFT на 62% с 40 до 15 секунд через внедрение асинхронной обработки и тюнинг векторного поиска. Решил проблему точности поиска сложной академической терминологии внедрив Hybrid Search на базе Dense и Sparse эмбеддингов что позволило устранить критические галлюцинации модели. Автоматизировал оцифровку сложных учебных материалов с формулами и таблицами разработав ETL пайплайн с использованием VLM воркфлоу и стратегий Semantic Chunking. Обеспечил высокую доступность системы и поддержку конкурентных сессий спроектировав масштабируемый бэкенд на FastAPI и Docker.', technologies=['Python', 'FastAPI', 'Docker', 'LangChain', 'Qdrant (VectorDB)', 'Redis', 'PostgreSQL', 'OpenAI API', 'Telegram API', 'Hybrid Search (BGE-M3, Gemini-001, Voyage-4)'])], education=[Education(institution='Казахстанско-Британский технический университет, Алматы', degree='Бакалавр', year='2025'), Education(institution='Школа Информационных Технологий и Инженерии', degree='Бакалавр', year='')], skills=['Python', 'SQL', 'PostgreSQL', 'Git', 'MySQL', 'langchain', 'NLP', 'LLM', 'PyTorch', 'pandas', 'Scikit-learn', 'Docker', 'FastAPI', 'RAG', 'ML', 'MLflow', 'AI agent', 'Matplotlib', 'Seaborn', 'AI', 'TensorFlow', 'API', 'Deep Learning', 'ChatGPT', 'PROMT', 'Numpy'], languages=['Казахский — Родной', 'Английский — C1 — Продвинутый', 'Русский — C2 — В совершенстве'])"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "004a782d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'full_name': 'Әшекей Нұрмұхамед',\n",
              " 'email': 'ashekeinureke@gmail.com',\n",
              " 'phone': '+7 (701) 1187021',\n",
              " 'links': ['https://github.com/NurmukhamedKZ',\n",
              "  'https://www.linkedin.com/in/nurmukhamed-ashekey-3031a3369/',\n",
              "  '@nureke3445'],\n",
              " 'location': ['Алматы'],\n",
              " 'summary': 'Я AI инженер с фокусом на разработку масштабируемых RAG систем и автономных AI агентов которые решают реальные задачи бизнеса.',\n",
              " 'total_experience_months': 16,\n",
              " 'work_history': [WorkExperience(role='AI Engineer', company='Slideble (Slideshow generator)', start_date='2025-09', end_date='Present', description='Сократил операционные расходы на генерацию слайд-шоу за счет оптимизации потребления токенов LLM на 30% через внедрение стратегий кэширования и продвинутого промпт-инжиниринга. Ускорил процесс отладки и итерации промптов на 40% и значительно повысил надежность системы инициировав и интегрировав пайплайнo bservability на базе LangSmith. Исключил 100% ошибок рендеринга сцен вызванных некорректными ответами моделей спроектировав архитектуру пайплайна структурированного вывода данных с жестким соблюдением JSON схем. Повысил фактологическую точность генерируемого контента проведя сравнительный анализ поисковых инструментов и интегрировав Tavily API для извлечения внешнего контекста.', technologies=['Python', 'OpenAI API', 'LangChain', 'LangGraph', 'LangSmith', 'PostgreSQL', 'SQLAlchemy', 'Tavily API', 'FastAPI']),\n",
              "  WorkExperience(role='AI Engineer', company='JauapAI (Educational RAG Platform)', start_date='2024-11', end_date='2025-09', description='Увеличил показатель удержания пользователей снизив время получения первого токена TTFT на 62% с 40 до 15 секунд через внедрение асинхронной обработки и тюнинг векторного поиска. Решил проблему точности поиска сложной академической терминологии внедрив Hybrid Search на базе Dense и Sparse эмбеддингов что позволило устранить критические галлюцинации модели. Автоматизировал оцифровку сложных учебных материалов с формулами и таблицами разработав ETL пайплайн с использованием VLM воркфлоу и стратегий Semantic Chunking. Обеспечил высокую доступность системы и поддержку конкурентных сессий спроектировав масштабируемый бэкенд на FastAPI и Docker.', technologies=['Python', 'FastAPI', 'Docker', 'LangChain', 'Qdrant (VectorDB)', 'Redis', 'PostgreSQL', 'OpenAI API', 'Telegram API', 'Hybrid Search (BGE-M3, Gemini-001, Voyage-4)'])],\n",
              " 'education': [Education(institution='Казахстанско-Британский технический университет, Алматы', degree='Бакалавр', year='2025'),\n",
              "  Education(institution='Школа Информационных Технологий и Инженерии', degree='Бакалавр', year='')],\n",
              " 'skills': ['Python',\n",
              "  'SQL',\n",
              "  'PostgreSQL',\n",
              "  'Git',\n",
              "  'MySQL',\n",
              "  'langchain',\n",
              "  'NLP',\n",
              "  'LLM',\n",
              "  'PyTorch',\n",
              "  'pandas',\n",
              "  'Scikit-learn',\n",
              "  'Docker',\n",
              "  'FastAPI',\n",
              "  'RAG',\n",
              "  'ML',\n",
              "  'MLflow',\n",
              "  'AI agent',\n",
              "  'Matplotlib',\n",
              "  'Seaborn',\n",
              "  'AI',\n",
              "  'TensorFlow',\n",
              "  'API',\n",
              "  'Deep Learning',\n",
              "  'ChatGPT',\n",
              "  'PROMT',\n",
              "  'Numpy'],\n",
              " 'languages': ['Казахский — Родной',\n",
              "  'Английский — C1 — Продвинутый',\n",
              "  'Русский — C2 — В совершенстве']}"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.__dict__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "7f815185",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_searchable_text(cv: CVOutput) -> str:\n",
        "    # 1. Собираем заголовок (Роль + Навыки)\n",
        "    main_info = f\"Candidate for {cv.work_history[0].role if cv.work_history else 'Professional'}. \"\n",
        "    skills = f\"Main Skills: {', '.join(cv.skills)}. \"\n",
        "    \n",
        "    # 2. Добавляем суммаризацию опыта (только суть задач)\n",
        "    exp_descriptions = []\n",
        "    for work in cv.work_history[:3]: # Берем последние 3 места работы\n",
        "        exp_descriptions.append(f\"{work.role} at {work.company}: {work.description}\")\n",
        "    \n",
        "    experience_text = \" Experience summary: \" + \" | \".join(exp_descriptions)\n",
        "    \n",
        "    # 3. Финальный текст для вектора\n",
        "    # Мы сознательно исключаем email, телефон и мелкие детали\n",
        "    search_text = main_info + skills + cv.summary + experience_text\n",
        "    \n",
        "    return search_text.lower() # Приводим к нижнему регистру для стабильности\n",
        "\n",
        "\n",
        "cv_text = create_searchable_text(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "23314887",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('candidate for ai engineer. main skills: python, sql, postgresql, git, mysql, '\n",
            " 'langchain, nlp, llm, pytorch, pandas, scikit-learn, docker, fastapi, rag, '\n",
            " 'ml, mlflow, ai agent, matplotlib, seaborn, ai, tensorflow, api, deep '\n",
            " 'learning, chatgpt, promt, numpy. я ai инженер с фокусом на разработку '\n",
            " 'масштабируемых rag систем и автономных ai агентов которые решают реальные '\n",
            " 'задачи бизнеса. experience summary: ai engineer at slideble (slideshow '\n",
            " 'generator): сократил операционные расходы на генерацию слайд-шоу за счет '\n",
            " 'оптимизации потребления токенов llm на 30% через внедрение стратегий '\n",
            " 'кэширования и продвинутого промпт-инжиниринга. ускорил процесс отладки и '\n",
            " 'итерации промптов на 40% и значительно повысил надежность системы '\n",
            " 'инициировав и интегрировав пайплайнo bservability на базе langsmith. '\n",
            " 'исключил 100% ошибок рендеринга сцен вызванных некорректными ответами '\n",
            " 'моделей спроектировав архитектуру пайплайна структурированного вывода данных '\n",
            " 'с жестким соблюдением json схем. повысил фактологическую точность '\n",
            " 'генерируемого контента проведя сравнительный анализ поисковых инструментов и '\n",
            " 'интегрировав tavily api для извлечения внешнего контекста. | ai engineer at '\n",
            " 'jauapai (educational rag platform): увеличил показатель удержания '\n",
            " 'пользователей снизив время получения первого токена ttft на 62% с 40 до 15 '\n",
            " 'секунд через внедрение асинхронной обработки и тюнинг векторного поиска. '\n",
            " 'решил проблему точности поиска сложной академической терминологии внедрив '\n",
            " 'hybrid search на базе dense и sparse эмбеддингов что позволило устранить '\n",
            " 'критические галлюцинации модели. автоматизировал оцифровку сложных учебных '\n",
            " 'материалов с формулами и таблицами разработав etl пайплайн с использованием '\n",
            " 'vlm воркфлоу и стратегий semantic chunking. обеспечил высокую доступность '\n",
            " 'системы и поддержку конкурентных сессий спроектировав масштабируемый бэкенд '\n",
            " 'на fastapi и docker.')\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(cv_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "a9522c80",
      "metadata": {},
      "outputs": [],
      "source": [
        "cv_emb_docs = [cv_text]\n",
        "cv_full_docs = [full_cv]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "04214d22",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collection 'HCB' already exists.\n"
          ]
        }
      ],
      "source": [
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "QDRANT_API = os.getenv(\"QDRANT_API\")\n",
        "QDRANT_URL = os.getenv(\"QDRANT_URL\")\n",
        "\n",
        "collection_name = \"HCB\"\n",
        "\n",
        "client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API)\n",
        "\n",
        "# 1. Создание коллекции (Hybrid)\n",
        "if not client.collection_exists(collection_name):\n",
        "    client.create_collection(\n",
        "        collection_name=collection_name,\n",
        "        vectors_config={\n",
        "            \"default\": models.VectorParams(\n",
        "                size=1024,\n",
        "                distance=models.Distance.COSINE\n",
        "            )\n",
        "        },\n",
        "        sparse_vectors_config={\n",
        "            \"sparse\": models.SparseVectorParams(\n",
        "                index=models.SparseIndexParams(on_disk=True)\n",
        "            )\n",
        "        }\n",
        "    )\n",
        "    print(f\"Collection '{collection_name}' created.\")\n",
        "else:\n",
        "    print(f\"Collection '{collection_name}' already exists.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdd3c066",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index created for nested field: 'metadata.location'\n",
            "Index created for nested field: 'metadata.experience'\n"
          ]
        }
      ],
      "source": [
        "# Note the \"metadata.\" prefix\n",
        "nested_fields = [\"metadata.location\", \"metadata.experience\"]\n",
        "\n",
        "for field in nested_fields:\n",
        "    client.create_payload_index(\n",
        "        collection_name=collection_name,\n",
        "        field_name=field,\n",
        "        field_schema=models.PayloadSchemaType.KEYWORD\n",
        "    )\n",
        "    print(f\"Index created for nested field: '{field}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "0d451884",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/nurma/vscode_projects/Bank_Home_Credit_Task/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'is_torch_fx_available' from 'transformers.utils.import_utils' (/Users/nurma/vscode_projects/Bank_Home_Credit_Task/.venv/lib/python3.13/site-packages/transformers/utils/import_utils.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[107]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mFlagEmbedding\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BGEM3FlagModel\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_voyageai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VoyageAIEmbeddings\n\u001b[32m      4\u001b[39m VOYAGE_API = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mVOYAGE_API\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/Bank_Home_Credit_Task/.venv/lib/python3.13/site-packages/FlagEmbedding/__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mabc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/Bank_Home_Credit_Task/.venv/lib/python3.13/site-packages/FlagEmbedding/inference/__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto_embedder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FlagAutoModel\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto_reranker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FlagAutoReranker\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01membedder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     FlagModel, BGEM3FlagModel,\n\u001b[32m      5\u001b[39m     FlagICLModel, FlagLLMModel,\n\u001b[32m      6\u001b[39m     EmbedderModelClass\n\u001b[32m      7\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreranker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     FlagReranker,\n\u001b[32m     10\u001b[39m     FlagLLMReranker, LayerWiseFlagLLMReranker, LightWeightFlagLLMReranker,\n\u001b[32m     11\u001b[39m     RerankerModelClass\n\u001b[32m     12\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/Bank_Home_Credit_Task/.venv/lib/python3.13/site-packages/FlagEmbedding/inference/auto_reranker.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Union, Optional\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mFlagEmbedding\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreranker\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_mapping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      6\u001b[39m     RerankerModelClass,\n\u001b[32m      7\u001b[39m     RERANKER_CLASS_MAPPING,\n\u001b[32m      8\u001b[39m     AUTO_RERANKER_MAPPING\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mFlagAutoReranker\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/Bank_Home_Credit_Task/.venv/lib/python3.13/site-packages/FlagEmbedding/inference/reranker/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdecoder_only\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FlagLLMReranker, LayerWiseFlagLLMReranker, LightWeightFlagLLMReranker\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mencoder_only\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FlagReranker\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_mapping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RerankerModelClass\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/Bank_Home_Credit_Task/.venv/lib/python3.13/site-packages/FlagEmbedding/inference/reranker/decoder_only/__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseLLMReranker \u001b[38;5;28;01mas\u001b[39;00m FlagLLMReranker\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayerwise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LayerWiseLLMReranker \u001b[38;5;28;01mas\u001b[39;00m LayerWiseFlagLLMReranker\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlightweight\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LightweightLLMReranker \u001b[38;5;28;01mas\u001b[39;00m LightWeightFlagLLMReranker\n\u001b[32m      5\u001b[39m __all__ = [\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFlagLLMReranker\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mLayerWiseFlagLLMReranker\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mLightWeightFlagLLMReranker\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m ]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/Bank_Home_Credit_Task/.venv/lib/python3.13/site-packages/FlagEmbedding/inference/reranker/decoder_only/layerwise.py:15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mFlagEmbedding\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreranker\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mencoder_only\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sigmoid\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mFlagEmbedding\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreranker\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdecoder_only\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatasetForReranker, Collater\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling_minicpm_reranker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LayerWiseMiniCPMForCausalLM\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlast_logit_pool_layerwise\u001b[39m(logits: Tensor,\n\u001b[32m     19\u001b[39m                               attention_mask: Tensor) -> Tensor:\n\u001b[32m     20\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Pool the last logit.\u001b[39;00m\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m \u001b[33;03m        torch.Tensor: The tensor after pooling.\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/Bank_Home_Credit_Task/.venv/lib/python3.13/site-packages/FlagEmbedding/inference/reranker/decoder_only/models/modeling_minicpm_reranker.py:53\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpytorch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ALL_LAYERNORM_LAYERS\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     46\u001b[39m     add_start_docstrings,\n\u001b[32m     47\u001b[39m     add_start_docstrings_to_model_forward,\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m     replace_return_docstrings,\n\u001b[32m     52\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimport_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_torch_fx_available\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_minicpm_reranker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LayerWiseMiniCPMConfig\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n",
            "\u001b[31mImportError\u001b[39m: cannot import name 'is_torch_fx_available' from 'transformers.utils.import_utils' (/Users/nurma/vscode_projects/Bank_Home_Credit_Task/.venv/lib/python3.13/site-packages/transformers/utils/import_utils.py)"
          ]
        }
      ],
      "source": [
        "from FlagEmbedding import BGEM3FlagModel\n",
        "from langchain_voyageai import VoyageAIEmbeddings\n",
        "\n",
        "VOYAGE_API = os.getenv(\"VOYAGE_API\")\n",
        "\n",
        "# Initialize Voyage Large\n",
        "dense_model = VoyageAIEmbeddings(\n",
        "    voyage_api_key=VOYAGE_API, \n",
        "    model=\"voyage-4-large\",\n",
        "    output_dimension=1024\n",
        ")\n",
        "\n",
        "sparse_model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)\n",
        "\n",
        "\n",
        "# EMBEDDING FUNCTIONS\n",
        "def sparse_documents(corpus, batch_size=32):\n",
        "    all_keys = []\n",
        "    all_vals = []\n",
        "    \n",
        "    # Process in small batches\n",
        "    for i in range(0, len(corpus), batch_size):\n",
        "        batch_text = corpus[i : i + batch_size]\n",
        "        output = sparse_model.encode(\n",
        "            batch_text,\n",
        "            return_dense=False, \n",
        "            return_sparse=True, \n",
        "            return_colbert_vecs=False\n",
        "        )\n",
        "        \n",
        "        for batch in output[\"lexical_weights\"]:\n",
        "            all_keys.append([int(k) for k in batch.keys()])\n",
        "            all_vals.append([float(v) for v in batch.values()])\n",
        "            \n",
        "    return all_keys, all_vals\n",
        "\n",
        "# Генерация векторов (Dense + Sparse)\n",
        "print(\"Dense embedding...\")\n",
        "dense_vectors = dense_model.embed_documents(cv_emb_docs)\n",
        "\n",
        "print(\"Sparse embedding...\")\n",
        "s_indices_batch, s_values_batch = sparse_documents(cv_emb_docs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52f916c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "def cv_to_payload(cv: CVOutput, full_text: str) -> dict:\n",
        "    \"\"\"Преобразует CVOutput в payload для Qdrant\"\"\"\n",
        "    \n",
        "    # Преобразуем вложенные объекты work_history в словари\n",
        "    work_history_dicts = [\n",
        "        {\n",
        "            \"role\": work.role,\n",
        "            \"company\": work.company,\n",
        "            \"start_date\": work.start_date,\n",
        "            \"end_date\": work.end_date,\n",
        "            \"description\": work.description,\n",
        "            \"technologies\": work.technologies\n",
        "        }\n",
        "        for work in cv.work_history\n",
        "    ]\n",
        "    \n",
        "    # Преобразуем education\n",
        "    education_dicts = [\n",
        "        {\n",
        "            \"institution\": edu.institution,\n",
        "            \"degree\": edu.degree,\n",
        "            \"year\": edu.year\n",
        "        }\n",
        "        for edu in cv.education\n",
        "    ]\n",
        "    \n",
        "    payload = {\n",
        "        \"full_content\": full_text,\n",
        "        \"full_name\": cv.full_name,\n",
        "        \"email\": cv.email,\n",
        "        \"phone\": cv.phone,\n",
        "        \"links\": cv.links,\n",
        "        \"location\": cv.location,\n",
        "        \"summary\": cv.summary,\n",
        "        \"total_experience_months\": cv.total_experience_months,\n",
        "        \"work_history\": work_history_dicts,\n",
        "        \"education\": education_dicts,\n",
        "        \"skills\": cv.skills,\n",
        "        \"languages\": cv.languages\n",
        "    }\n",
        "    \n",
        "    return payload\n",
        "\n",
        "# Создаем payload\n",
        "payload = cv_to_payload(response, full_cv)\n",
        "\n",
        "# Проверяем структуру\n",
        "print(\"Пример payload:\")\n",
        "print(f\"Full name: {payload['full_name']}\")\n",
        "print(f\"Email: {payload['email']}\")\n",
        "print(f\"Phone: {payload['phone']}\")\n",
        "print(f\"Total experience: {payload['total_experience_months']} months\")\n",
        "print(f\"Skills count: {len(payload['skills'])}\")\n",
        "print(f\"Work history entries: {len(payload['work_history'])}\")\n",
        "print(f\"\\nПервая позиция:\")\n",
        "print(f\"  {payload['work_history'][0]['role']} at {payload['work_history'][0]['company']}\") \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8d5b7a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "# Создаем UUID для каждого CV\n",
        "point_ids = [str(uuid.uuid4()) for _ in cv_full_docs]\n",
        "\n",
        "# Создаем points для Qdrant\n",
        "points = [\n",
        "    models.PointStruct(\n",
        "        id=point_ids[i],\n",
        "        vector={\n",
        "            \"default\": dense,\n",
        "            \"sparse\": models.SparseVector(indices=keys, values=vals)\n",
        "        },\n",
        "        payload=payload  # Используем созданный payload\n",
        "    ) \n",
        "    for i, (dense, keys, vals) in enumerate(zip(dense_vectors, s_indices_batch, s_values_batch, strict=True))\n",
        "]\n",
        "\n",
        "print(f\"Создано {len(points)} points для загрузки в Qdrant\")\n",
        "print(f\"\\nПример point:\")\n",
        "print(f\"ID: {points[0].id}\")\n",
        "print(f\"Vector dimensions: {len(points[0].vector['default'])}\")\n",
        "print(f\"Sparse vector size: {len(points[0].vector['sparse'].indices)}\")\n",
        "print(f\"Payload keys: {list(points[0].payload.keys())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2f1bc72",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Загружаем в Qdrant\n",
        "operation_info = client.upsert(\n",
        "    collection_name=collection_name,\n",
        "    points=points,\n",
        "    wait=True\n",
        ")\n",
        "\n",
        "print(f\"✅ Успешно загружено {len(points)} CV в Qdrant!\")\n",
        "print(f\"Operation status: {operation_info.status}\")\n",
        "\n",
        "# Проверяем что данные загрузились\n",
        "collection_info = client.get_collection(collection_name)\n",
        "print(f\"\\nТеперь в коллекции '{collection_name}' всего {collection_info.points_count} точек\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5cc4436",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Тестовый поиск: проверяем что данные доступны\n",
        "test_results = client.scroll(\n",
        "    collection_name=collection_name,\n",
        "    limit=1,\n",
        "    with_payload=True,\n",
        "    with_vectors=False\n",
        ")\n",
        "\n",
        "if test_results[0]:\n",
        "    print(\"Пример загруженного CV из Qdrant:\\n\")\n",
        "    point = test_results[0][0]\n",
        "    \n",
        "    print(f\"ID: {point.id}\")\n",
        "    print(f\"Имя: {point.payload.get('full_name')}\")\n",
        "    print(f\"Email: {point.payload.get('email')}\")\n",
        "    print(f\"Телефон: {point.payload.get('phone')}\")\n",
        "    print(f\"Локация: {point.payload.get('location')}\")\n",
        "    print(f\"Опыт: {point.payload.get('total_experience_months')} месяцев\")\n",
        "    print(f\"Навыки ({len(point.payload.get('skills', []))}): {', '.join(point.payload.get('skills', [])[:10])}...\")\n",
        "    print(f\"\\nРабочая история:\")\n",
        "    for i, work in enumerate(point.payload.get('work_history', [])[:2], 1):\n",
        "        print(f\"  {i}. {work['role']} at {work['company']}\")\n",
        "        print(f\"     {work['start_date']} - {work['end_date']}\")\n",
        "        print(f\"     Tech: {', '.join(work['technologies'][:5])}...\")\n",
        "else:\n",
        "    print(\"Данные не найдены\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.13.5)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
