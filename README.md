# CVParser - –ü–∞—Ä—Å–µ—Ä —Ä–µ–∑—é–º–µ —Å AI –∏ –≤–µ–∫—Ç–æ—Ä–Ω—ã–º –ø–æ–∏—Å–∫–æ–º

–ö–ª–∞—Å—Å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—é–º–µ: –ø–∞—Ä—Å–∏–Ω–≥ PDF/DOCX, –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ LLM –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö Qdrant.

## üöÄ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- ‚úÖ **–ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–æ–≤**: PDF (—á–µ—Ä–µ–∑ LlamaParse), DOCX, TXT
- ‚úÖ **–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö**: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ GPT-4o-mini
- ‚úÖ **–í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫**: Hybrid search (dense + sparse embeddings)
- ‚úÖ **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Qdrant**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –∏ –∏–Ω–¥–µ–∫—Å–æ–≤
- ‚úÖ **–ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω**: –û–¥–∏–Ω –º–µ—Ç–æ–¥ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç —Ñ–∞–π–ª–∞ –¥–æ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö

## üì¶ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö

–ö–∞–∂–¥–æ–µ CV –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç—Å—è –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π JSON —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –ø–æ–ª—è–º–∏:

```python
{
    "full_name": str,
    "email": str,
    "phone": str,
    "links": [str],  # GitHub, LinkedIn, Portfolio
    "location": [str],
    "summary": str,  # –ö—Ä–∞—Ç–∫–æ–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Ä–µ–∑—é–º–µ
    "total_experience_months": int,
    "work_history": [
        {
            "role": str,
            "company": str,
            "start_date": str,  # YYYY-MM
            "end_date": str,  # YYYY-MM –∏–ª–∏ "Present"
            "description": str,
            "technologies": [str]
        }
    ],
    "education": [
        {
            "institution": str,
            "degree": str,
            "year": str
        }
    ],
    "skills": [str],
    "languages": [str]
}
```

## üîß –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
pip install llama-parse
pip install langchain langchain-openai langchain-voyageai
pip install qdrant-client
pip install FlagEmbedding
pip install python-dotenv
```

## üîë –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `.env` –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞:

```env
# LlamaParse –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ PDF
LLAMA_PARSE_API=your_llama_parse_api_key

# OpenAI –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
OPENAI_API_KEY=your_openai_api_key

# Qdrant –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
QDRANT_API=your_qdrant_api_key
QDRANT_URL=your_qdrant_url

# Voyage AI –¥–ª—è dense embeddings
VOYAGE_API=your_voyage_api_key
```

## üí° –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ (–æ–¥–∏–Ω —Ñ–∞–π–ª)

```python
from Parse_pdf import CVParser

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
parser = CVParser(collection_name="CVs")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ CV (–ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω)
result = parser.process_cv("path/to/resume.pdf")

print(f"–ò–º—è: {result['full_name']}")
print(f"Email: {result['email']}")
print(f"–û–ø—ã—Ç: {result['total_experience_months']} –º–µ—Å—è—Ü–µ–≤")
```

### –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

```python
from pathlib import Path

parser = CVParser(collection_name="CVs")

# –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ PDF –≤ –ø–∞–ø–∫–µ
cvs_folder = Path("data/CVs")
for pdf_file in cvs_folder.glob("*.pdf"):
    try:
        result = parser.process_cv(pdf_file)
        print(f"‚úÖ {result['full_name']} –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
```

### –ü–æ—à–∞–≥–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

–ï—Å–ª–∏ –Ω—É–∂–µ–Ω –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ:

```python
parser = CVParser(collection_name="CVs")

# –®–∞–≥ 1: –ü–∞—Ä—Å–∏–º —Ñ–∞–π–ª
full_text = parser.parse_file("resume.pdf")

# –®–∞–≥ 2: –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
cv_data = parser.extract_cv_data(full_text)

# –®–∞–≥ 3: –°–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞
searchable_text = parser.create_searchable_text(cv_data)

# –®–∞–≥ 4: –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
dense_vec, sparse_idx, sparse_val = parser.create_embeddings(searchable_text)

# –®–∞–≥ 5: –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Qdrant
point_id = parser.save_to_qdrant(
    cv_data=cv_data,
    full_text=full_text,
    dense_vector=dense_vec,
    sparse_indices=sparse_idx,
    sparse_values=sparse_val
)
```

### –ü–æ–∏—Å–∫ –≤ Qdrant

```python
parser = CVParser(collection_name="CVs")

# –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
query = "Python developer with FastAPI and PostgreSQL"
dense_vec, sparse_idx, sparse_val = parser.create_embeddings(query)

# Hybrid search
results = parser.qdrant_client.query_points(
    collection_name="CVs",
    query=dense_vec,
    using="default",
    limit=5,
    with_payload=True
)

# –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
for point in results.points:
    print(f"{point.payload['full_name']} - Score: {point.score:.4f}")
    print(f"Skills: {', '.join(point.payload['skills'][:5])}")
```

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
CVParser
‚îú‚îÄ‚îÄ parse_file()              # –ü–∞—Ä—Å–∏–Ω–≥ PDF/DOCX/TXT
‚îú‚îÄ‚îÄ extract_cv_data()         # –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ LLM
‚îú‚îÄ‚îÄ create_searchable_text()  # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
‚îú‚îÄ‚îÄ create_embeddings()       # Dense + Sparse –≤–µ–∫—Ç–æ—Ä—ã
‚îú‚îÄ‚îÄ save_to_qdrant()         # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î
‚îî‚îÄ‚îÄ process_cv()             # –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω (–≤—Å—ë –≤–º–µ—Å—Ç–µ)
```

## üîç –ú–æ–¥–µ–ª–∏ –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏

- **–ü–∞—Ä—Å–∏–Ω–≥ PDF**: LlamaParse (—Å OCR –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã)
- **–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ**: GPT-4o-mini —á–µ—Ä–µ–∑ LangChain
- **Dense Embeddings**: Voyage AI (voyage-4-large, 1024 dim)
- **Sparse Embeddings**: BGE-M3 (BM25-like)
- **–í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î**: Qdrant (Hybrid Search)

## üìä –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

- –ü–∞—Ä—Å–∏–Ω–≥ PDF: ~10-30 —Å–µ–∫—É–Ω–¥ (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–∞–∑–º–µ—Ä–∞)
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ LLM: ~5-10 —Å–µ–∫—É–Ω–¥
- –≠–º–±–µ–¥–¥–∏–Ω–≥–∏: ~2-5 —Å–µ–∫—É–Ω–¥
- **–ò—Ç–æ–≥–æ**: ~20-45 —Å–µ–∫—É–Ω–¥ –Ω–∞ –æ–¥–Ω–æ CV

## üõ†Ô∏è –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ

### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ DOCX

```python
def parse_docx(self, file_path: str | Path) -> str:
    from docx import Document
    
    doc = Document(file_path)
    full_text = []
    
    for paragraph in doc.paragraphs:
        full_text.append(paragraph.text)
    
    return "\n".join(full_text)
```

### –ö–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è System Prompt

```python
parser = CVParser(collection_name="CVs")

# –ò–∑–º–µ–Ω—è–µ–º –ø—Ä–æ–º–ø—Ç
parser.system_prompt = """
Your custom instructions for CV parsing...
"""

# –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º —Ü–µ–ø–æ—á–∫—É
parser.prompt = ChatPromptTemplate.from_messages([
    ("system", parser.system_prompt),
    ("user", "Resume:\n\n{text}")
])
parser.chain = parser.prompt | parser.structured_llm
```

### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø–æ–ª–µ–π –≤ CVOutput

```python
class CVOutput(BaseModel):
    # –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è...
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ –ø–æ–ª–µ
    certifications: List[str] = Field(
        default_factory=list,
        description="Professional certifications"
    )
```

## üêõ Troubleshooting

### –û—à–∏–±–∫–∞: "Collection already exists"
–ö–æ–ª–ª–µ–∫—Ü–∏—è —Å–æ–∑–¥–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏. –ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å:

```python
parser.qdrant_client.delete_collection("CVs")
parser._ensure_collection(1024)
```

### –û—à–∏–±–∫–∞: "File not found"
–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É:

```python
from pathlib import Path
file_path = Path("data/CVs/resume.pdf")
print(f"–°—É—â–µ—Å—Ç–≤—É–µ—Ç: {file_path.exists()}")
print(f"–ê–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å: {file_path.absolute()}")
```

### –ú–µ–¥–ª–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ batch processing –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö CV
- –ö—ç—à–∏—Ä—É–π—Ç–µ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
- –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É

## üìù –õ–∏—Ü–µ–Ω–∑–∏—è

MIT

## üë®‚Äçüíª –ê–≤—Ç–æ—Ä

–°–æ–∑–¥–∞–Ω–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ jupyter notebook `research/CV_parser.ipynb`
